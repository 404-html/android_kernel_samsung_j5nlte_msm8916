%2F*%0A%20*%09Routines%20having%20to%20do%20with%20the%20'struct%20sk_buff'%20memory%20handlers.%0A%20*%0A%20*%09Authors%3A%09Alan%20Cox%20%3Calan%40lxorguk.ukuu.org.uk%3E%0A%20*%09%09%09Florian%20La%20Roche%20%3Crzsfl%40rz.uni-sb.de%3E%0A%20*%0A%20*%09Fixes%3A%0A%20*%09%09Alan%20Cox%09%3A%09Fixed%20the%20worst%20of%20the%20load%0A%20*%09%09%09%09%09balancer%20bugs.%0A%20*%09%09Dave%20Platt%09%3A%09Interrupt%20stacking%20fix.%0A%20*%09Richard%20Kooijman%09%3A%09Timestamp%20fixes.%0A%20*%09%09Alan%20Cox%09%3A%09Changed%20buffer%20format.%0A%20*%09%09Alan%20Cox%09%3A%09destructor%20hook%20for%20AF_UNIX%20etc.%0A%20*%09%09Linus%20Torvalds%09%3A%09Better%20skb_clone.%0A%20*%09%09Alan%20Cox%09%3A%09Added%20skb_copy.%0A%20*%09%09Alan%20Cox%09%3A%09Added%20all%20the%20changed%20routines%20Linus%0A%20*%09%09%09%09%09only%20put%20in%20the%20headers%0A%20*%09%09Ray%20VanTassle%09%3A%09Fixed%20--skb-%3Elock%20in%20free%0A%20*%09%09Alan%20Cox%09%3A%09skb_copy%20copy%20arp%20field%0A%20*%09%09Andi%20Kleen%09%3A%09slabified%20it.%0A%20*%09%09Robert%20Olsson%09%3A%09Removed%20skb_head_pool%0A%20*%0A%20*%09NOTE%3A%0A%20*%09%09The%20__skb_%20routines%20should%20be%20called%20with%20interrupts%0A%20*%09disabled%2C%20or%20you%20better%20be%20*real*%20sure%20that%20the%20operation%20is%20atomic%0A%20*%09with%20respect%20to%20whatever%20list%20is%20being%20frobbed%20(e.g.%20via%20lock_sock()%0A%20*%09or%20via%20disabling%20bottom%20half%20handlers%2C%20etc).%0A%20*%0A%20*%09This%20program%20is%20free%20software%3B%20you%20can%20redistribute%20it%20and%2For%0A%20*%09modify%20it%20under%20the%20terms%20of%20the%20GNU%20General%20Public%20License%0A%20*%09as%20published%20by%20the%20Free%20Software%20Foundation%3B%20either%20version%0A%20*%092%20of%20the%20License%2C%20or%20(at%20your%20option)%20any%20later%20version.%0A%20*%2F%0A%0A%2F*%0A%20*%09The%20functions%20in%20this%20file%20will%20not%20compile%20correctly%20with%20gcc%202.4.x%0A%20*%2F%0A%0A%23define%20pr_fmt(fmt)%20KBUILD_MODNAME%20%22%3A%20%22%20fmt%0A%0A%23include%20%3Clinux%2Fmodule.h%3E%0A%23include%20%3Clinux%2Ftypes.h%3E%0A%23include%20%3Clinux%2Fkernel.h%3E%0A%23include%20%3Clinux%2Fkmemcheck.h%3E%0A%23include%20%3Clinux%2Fmm.h%3E%0A%23include%20%3Clinux%2Finterrupt.h%3E%0A%23include%20%3Clinux%2Fin.h%3E%0A%23include%20%3Clinux%2Finet.h%3E%0A%23include%20%3Clinux%2Fslab.h%3E%0A%23include%20%3Clinux%2Fnetdevice.h%3E%0A%23ifdef%20CONFIG_NET_CLS_ACT%0A%23include%20%3Cnet%2Fpkt_sched.h%3E%0A%23endif%0A%23include%20%3Clinux%2Fstring.h%3E%0A%23include%20%3Clinux%2Fskbuff.h%3E%0A%23include%20%3Clinux%2Fsplice.h%3E%0A%23include%20%3Clinux%2Fcache.h%3E%0A%23include%20%3Clinux%2Frtnetlink.h%3E%0A%23include%20%3Clinux%2Finit.h%3E%0A%23include%20%3Clinux%2Fscatterlist.h%3E%0A%23include%20%3Clinux%2Ferrqueue.h%3E%0A%23include%20%3Clinux%2Fprefetch.h%3E%0A%0A%23include%20%3Cnet%2Fprotocol.h%3E%0A%23include%20%3Cnet%2Fdst.h%3E%0A%23include%20%3Cnet%2Fsock.h%3E%0A%23include%20%3Cnet%2Fchecksum.h%3E%0A%23include%20%3Cnet%2Fxfrm.h%3E%0A%0A%23include%20%3Casm%2Fuaccess.h%3E%0A%23include%20%3Ctrace%2Fevents%2Fskb.h%3E%0A%23include%20%3Clinux%2Fhighmem.h%3E%0A%0Astruct%20kmem_cache%20*skbuff_head_cache%20__read_mostly%3B%0Astatic%20struct%20kmem_cache%20*skbuff_fclone_cache%20__read_mostly%3B%0A%0Astatic%20void%20sock_pipe_buf_release(struct%20pipe_inode_info%20*pipe%2C%0A%09%09%09%09%20%20struct%20pipe_buffer%20*buf)%0A%7B%0A%09put_page(buf-%3Epage)%3B%0A%7D%0A%0Astatic%20void%20sock_pipe_buf_get(struct%20pipe_inode_info%20*pipe%2C%0A%09%09%09%09struct%20pipe_buffer%20*buf)%0A%7B%0A%09get_page(buf-%3Epage)%3B%0A%7D%0A%0Astatic%20int%20sock_pipe_buf_steal(struct%20pipe_inode_info%20*pipe%2C%0A%09%09%09%20%20%20%20%20%20%20struct%20pipe_buffer%20*buf)%0A%7B%0A%09return%201%3B%0A%7D%0A%0A%0A%2F*%20Pipe%20buffer%20operations%20for%20a%20socket.%20*%2F%0Astatic%20const%20struct%20pipe_buf_operations%20sock_pipe_buf_ops%20%3D%20%7B%0A%09.can_merge%20%3D%200%2C%0A%09.map%20%3D%20generic_pipe_buf_map%2C%0A%09.unmap%20%3D%20generic_pipe_buf_unmap%2C%0A%09.confirm%20%3D%20generic_pipe_buf_confirm%2C%0A%09.release%20%3D%20sock_pipe_buf_release%2C%0A%09.steal%20%3D%20sock_pipe_buf_steal%2C%0A%09.get%20%3D%20sock_pipe_buf_get%2C%0A%7D%3B%0A%0A%2F**%0A%20*%09skb_panic%20-%20private%20function%20for%20out-of-line%20support%0A%20*%09%40skb%3A%09buffer%0A%20*%09%40sz%3A%09size%0A%20*%09%40addr%3A%09address%0A%20*%09%40msg%3A%09skb_over_panic%20or%20skb_under_panic%0A%20*%0A%20*%09Out-of-line%20support%20for%20skb_put()%20and%20skb_push().%0A%20*%09Called%20via%20the%20wrapper%20skb_over_panic()%20or%20skb_under_panic().%0A%20*%09Keep%20out%20of%20line%20to%20prevent%20kernel%20bloat.%0A%20*%09__builtin_return_address%20is%20not%20used%20because%20it%20is%20not%20always%20reliable.%0A%20*%2F%0Astatic%20void%20skb_panic(struct%20sk_buff%20*skb%2C%20unsigned%20int%20sz%2C%20void%20*addr%2C%0A%09%09%20%20%20%20%20%20const%20char%20msg%5B%5D)%0A%7B%0A%09pr_emerg(%22%25s%3A%20text%3A%25p%20len%3A%25d%20put%3A%25d%20head%3A%25p%20data%3A%25p%20tail%3A%25%23lx%20end%3A%25%23lx%20dev%3A%25s%5Cn%22%2C%0A%09%09%20msg%2C%20addr%2C%20skb-%3Elen%2C%20sz%2C%20skb-%3Ehead%2C%20skb-%3Edata%2C%0A%09%09%20(unsigned%20long)skb-%3Etail%2C%20(unsigned%20long)skb-%3Eend%2C%0A%09%09%20skb-%3Edev%20%3F%20skb-%3Edev-%3Ename%20%3A%20%22%3CNULL%3E%22)%3B%0A%09BUG()%3B%0A%7D%0A%0Astatic%20void%20skb_over_panic(struct%20sk_buff%20*skb%2C%20unsigned%20int%20sz%2C%20void%20*addr)%0A%7B%0A%09skb_panic(skb%2C%20sz%2C%20addr%2C%20__func__)%3B%0A%7D%0A%0Astatic%20void%20skb_under_panic(struct%20sk_buff%20*skb%2C%20unsigned%20int%20sz%2C%20void%20*addr)%0A%7B%0A%09skb_panic(skb%2C%20sz%2C%20addr%2C%20__func__)%3B%0A%7D%0A%0A%2F*%0A%20*%20kmalloc_reserve%20is%20a%20wrapper%20around%20kmalloc_node_track_caller%20that%20tells%0A%20*%20the%20caller%20if%20emergency%20pfmemalloc%20reserves%20are%20being%20used.%20If%20it%20is%20and%0A%20*%20the%20socket%20is%20later%20found%20to%20be%20SOCK_MEMALLOC%20then%20PFMEMALLOC%20reserves%0A%20*%20may%20be%20used.%20Otherwise%2C%20the%20packet%20data%20may%20be%20discarded%20until%20enough%0A%20*%20memory%20is%20free%0A%20*%2F%0A%23define%20kmalloc_reserve(size%2C%20gfp%2C%20node%2C%20pfmemalloc)%20%5C%0A%09%20__kmalloc_reserve(size%2C%20gfp%2C%20node%2C%20_RET_IP_%2C%20pfmemalloc)%0A%0Astatic%20void%20*__kmalloc_reserve(size_t%20size%2C%20gfp_t%20flags%2C%20int%20node%2C%0A%09%09%09%20%20%20%20%20%20%20unsigned%20long%20ip%2C%20bool%20*pfmemalloc)%0A%7B%0A%09void%20*obj%3B%0A%09bool%20ret_pfmemalloc%20%3D%20false%3B%0A%0A%09%2F*%0A%09%20*%20Try%20a%20regular%20allocation%2C%20when%20that%20fails%20and%20we're%20not%20entitled%0A%09%20*%20to%20the%20reserves%2C%20fail.%0A%09%20*%2F%0A%09obj%20%3D%20kmalloc_node_track_caller(size%2C%0A%09%09%09%09%09flags%20%7C%20__GFP_NOMEMALLOC%20%7C%20__GFP_NOWARN%2C%0A%09%09%09%09%09node)%3B%0A%09if%20(obj%20%7C%7C%20!(gfp_pfmemalloc_allowed(flags)))%0A%09%09goto%20out%3B%0A%0A%09%2F*%20Try%20again%20but%20now%20we%20are%20using%20pfmemalloc%20reserves%20*%2F%0A%09ret_pfmemalloc%20%3D%20true%3B%0A%09obj%20%3D%20kmalloc_node_track_caller(size%2C%20flags%2C%20node)%3B%0A%0Aout%3A%0A%09if%20(pfmemalloc)%0A%09%09*pfmemalloc%20%3D%20ret_pfmemalloc%3B%0A%0A%09return%20obj%3B%0A%7D%0A%0A%2F*%20%09Allocate%20a%20new%20skbuff.%20We%20do%20this%20ourselves%20so%20we%20can%20fill%20in%20a%20few%0A%20*%09'private'%20fields%20and%20also%20do%20memory%20statistics%20to%20find%20all%20the%0A%20*%09%5BBEEP%5D%20leaks.%0A%20*%0A%20*%2F%0A%0Astruct%20sk_buff%20*__alloc_skb_head(gfp_t%20gfp_mask%2C%20int%20node)%0A%7B%0A%09struct%20sk_buff%20*skb%3B%0A%0A%09%2F*%20Get%20the%20HEAD%20*%2F%0A%09skb%20%3D%20kmem_cache_alloc_node(skbuff_head_cache%2C%0A%09%09%09%09%20%20%20%20gfp_mask%20%26%20~__GFP_DMA%2C%20node)%3B%0A%09if%20(!skb)%0A%09%09goto%20out%3B%0A%0A%09%2F*%0A%09%20*%20Only%20clear%20those%20fields%20we%20need%20to%20clear%2C%20not%20those%20that%20we%20will%0A%09%20*%20actually%20initialise%20below.%20Hence%2C%20don't%20put%20any%20more%20fields%20after%0A%09%20*%20the%20tail%20pointer%20in%20struct%20sk_buff!%0A%09%20*%2F%0A%09memset(skb%2C%200%2C%20offsetof(struct%20sk_buff%2C%20tail))%3B%0A%09skb-%3Ehead%20%3D%20NULL%3B%0A%09skb-%3Etruesize%20%3D%20sizeof(struct%20sk_buff)%3B%0A%09atomic_set(%26skb-%3Eusers%2C%201)%3B%0A%0A%23ifdef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb-%3Emac_header%20%3D%20~0U%3B%0A%23endif%0Aout%3A%0A%09return%20skb%3B%0A%7D%0A%0A%2F**%0A%20*%09__alloc_skb%09-%09allocate%20a%20network%20buffer%0A%20*%09%40size%3A%20size%20to%20allocate%0A%20*%09%40gfp_mask%3A%20allocation%20mask%0A%20*%09%40flags%3A%20If%20SKB_ALLOC_FCLONE%20is%20set%2C%20allocate%20from%20fclone%20cache%0A%20*%09%09instead%20of%20head%20cache%20and%20allocate%20a%20cloned%20(child)%20skb.%0A%20*%09%09If%20SKB_ALLOC_RX%20is%20set%2C%20__GFP_MEMALLOC%20will%20be%20used%20for%0A%20*%09%09allocations%20in%20case%20the%20data%20is%20required%20for%20writeback%0A%20*%09%40node%3A%20numa%20node%20to%20allocate%20memory%20on%0A%20*%0A%20*%09Allocate%20a%20new%20%26sk_buff.%20The%20returned%20buffer%20has%20no%20headroom%20and%20a%0A%20*%09tail%20room%20of%20at%20least%20size%20bytes.%20The%20object%20has%20a%20reference%20count%0A%20*%09of%20one.%20The%20return%20is%20the%20buffer.%20On%20a%20failure%20the%20return%20is%20%25NULL.%0A%20*%0A%20*%09Buffers%20may%20only%20be%20allocated%20from%20interrupts%20using%20a%20%40gfp_mask%20of%0A%20*%09%25GFP_ATOMIC.%0A%20*%2F%0Astruct%20sk_buff%20*__alloc_skb(unsigned%20int%20size%2C%20gfp_t%20gfp_mask%2C%0A%09%09%09%20%20%20%20int%20flags%2C%20int%20node)%0A%7B%0A%09struct%20kmem_cache%20*cache%3B%0A%09struct%20skb_shared_info%20*shinfo%3B%0A%09struct%20sk_buff%20*skb%3B%0A%09u8%20*data%3B%0A%09bool%20pfmemalloc%3B%0A%0A%09cache%20%3D%20(flags%20%26%20SKB_ALLOC_FCLONE)%0A%09%09%3F%20skbuff_fclone_cache%20%3A%20skbuff_head_cache%3B%0A%0A%09if%20(sk_memalloc_socks()%20%26%26%20(flags%20%26%20SKB_ALLOC_RX))%0A%09%09gfp_mask%20%7C%3D%20__GFP_MEMALLOC%3B%0A%0A%09%2F*%20Get%20the%20HEAD%20*%2F%0A%09skb%20%3D%20kmem_cache_alloc_node(cache%2C%20gfp_mask%20%26%20~__GFP_DMA%2C%20node)%3B%0A%09if%20(!skb)%0A%09%09goto%20out%3B%0A%09prefetchw(skb)%3B%0A%0A%09%2F*%20We%20do%20our%20best%20to%20align%20skb_shared_info%20on%20a%20separate%20cache%0A%09%20*%20line.%20It%20usually%20works%20because%20kmalloc(X%20%3E%20SMP_CACHE_BYTES)%20gives%0A%09%20*%20aligned%20memory%20blocks%2C%20unless%20SLUB%2FSLAB%20debug%20is%20enabled.%0A%09%20*%20Both%20skb-%3Ehead%20and%20skb_shared_info%20are%20cache%20line%20aligned.%0A%09%20*%2F%0A%09size%20%3D%20SKB_DATA_ALIGN(size)%3B%0A%09size%20%2B%3D%20SKB_DATA_ALIGN(sizeof(struct%20skb_shared_info))%3B%0A%09data%20%3D%20kmalloc_reserve(size%2C%20gfp_mask%2C%20node%2C%20%26pfmemalloc)%3B%0A%09if%20(unlikely(ZERO_OR_NULL_PTR(data)))%0A%09%09goto%20nodata%3B%0A%09%2F*%20kmalloc(size)%20might%20give%20us%20more%20room%20than%20requested.%0A%09%20*%20Put%20skb_shared_info%20exactly%20at%20the%20end%20of%20allocated%20zone%2C%0A%09%20*%20to%20allow%20max%20possible%20filling%20before%20reallocation.%0A%09%20*%2F%0A%09size%20%3D%20SKB_WITH_OVERHEAD(ksize(data))%3B%0A%09prefetchw(data%20%2B%20size)%3B%0A%0A%09%2F*%0A%09%20*%20Only%20clear%20those%20fields%20we%20need%20to%20clear%2C%20not%20those%20that%20we%20will%0A%09%20*%20actually%20initialise%20below.%20Hence%2C%20don't%20put%20any%20more%20fields%20after%0A%09%20*%20the%20tail%20pointer%20in%20struct%20sk_buff!%0A%09%20*%2F%0A%09memset(skb%2C%200%2C%20offsetof(struct%20sk_buff%2C%20tail))%3B%0A%09%2F*%20Account%20for%20allocated%20memory%20%3A%20skb%20%2B%20skb-%3Ehead%20*%2F%0A%09skb-%3Etruesize%20%3D%20SKB_TRUESIZE(size)%3B%0A%09skb-%3Epfmemalloc%20%3D%20pfmemalloc%3B%0A%09atomic_set(%26skb-%3Eusers%2C%201)%3B%0A%09skb-%3Ehead%20%3D%20data%3B%0A%09skb-%3Edata%20%3D%20data%3B%0A%09skb_reset_tail_pointer(skb)%3B%0A%09skb-%3Eend%20%3D%20skb-%3Etail%20%2B%20size%3B%0A%23ifdef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb-%3Emac_header%20%3D%20~0U%3B%0A%09skb-%3Etransport_header%20%3D%20~0U%3B%0A%23endif%0A%0A%09%2F*%20make%20sure%20we%20initialize%20shinfo%20sequentially%20*%2F%0A%09shinfo%20%3D%20skb_shinfo(skb)%3B%0A%09memset(shinfo%2C%200%2C%20offsetof(struct%20skb_shared_info%2C%20dataref))%3B%0A%09atomic_set(%26shinfo-%3Edataref%2C%201)%3B%0A%09kmemcheck_annotate_variable(shinfo-%3Edestructor_arg)%3B%0A%0A%09if%20(flags%20%26%20SKB_ALLOC_FCLONE)%20%7B%0A%09%09struct%20sk_buff%20*child%20%3D%20skb%20%2B%201%3B%0A%09%09atomic_t%20*fclone_ref%20%3D%20(atomic_t%20*)%20(child%20%2B%201)%3B%0A%0A%09%09kmemcheck_annotate_bitfield(child%2C%20flags1)%3B%0A%09%09kmemcheck_annotate_bitfield(child%2C%20flags2)%3B%0A%09%09skb-%3Efclone%20%3D%20SKB_FCLONE_ORIG%3B%0A%09%09atomic_set(fclone_ref%2C%201)%3B%0A%0A%09%09child-%3Efclone%20%3D%20SKB_FCLONE_UNAVAILABLE%3B%0A%09%09child-%3Epfmemalloc%20%3D%20pfmemalloc%3B%0A%09%7D%0Aout%3A%0A%09return%20skb%3B%0Anodata%3A%0A%09kmem_cache_free(cache%2C%20skb)%3B%0A%09skb%20%3D%20NULL%3B%0A%09goto%20out%3B%0A%7D%0AEXPORT_SYMBOL(__alloc_skb)%3B%0A%0A%2F**%0A%20*%20build_skb%20-%20build%20a%20network%20buffer%0A%20*%20%40data%3A%20data%20buffer%20provided%20by%20caller%0A%20*%20%40frag_size%3A%20size%20of%20fragment%2C%20or%200%20if%20head%20was%20kmalloced%0A%20*%0A%20*%20Allocate%20a%20new%20%26sk_buff.%20Caller%20provides%20space%20holding%20head%20and%0A%20*%20skb_shared_info.%20%40data%20must%20have%20been%20allocated%20by%20kmalloc()%0A%20*%20The%20return%20is%20the%20new%20skb%20buffer.%0A%20*%20On%20a%20failure%20the%20return%20is%20%25NULL%2C%20and%20%40data%20is%20not%20freed.%0A%20*%20Notes%20%3A%0A%20*%20%20Before%20IO%2C%20driver%20allocates%20only%20data%20buffer%20where%20NIC%20put%20incoming%20frame%0A%20*%20%20Driver%20should%20add%20room%20at%20head%20(NET_SKB_PAD)%20and%0A%20*%20%20MUST%20add%20room%20at%20tail%20(SKB_DATA_ALIGN(skb_shared_info))%0A%20*%20%20After%20IO%2C%20driver%20calls%20build_skb()%2C%20to%20allocate%20sk_buff%20and%20populate%20it%0A%20*%20%20before%20giving%20packet%20to%20stack.%0A%20*%20%20RX%20rings%20only%20contains%20data%20buffers%2C%20not%20full%20skbs.%0A%20*%2F%0Astruct%20sk_buff%20*build_skb(void%20*data%2C%20unsigned%20int%20frag_size)%0A%7B%0A%09struct%20skb_shared_info%20*shinfo%3B%0A%09struct%20sk_buff%20*skb%3B%0A%09unsigned%20int%20size%20%3D%20frag_size%20%3F%20%3A%20ksize(data)%3B%0A%0A%09skb%20%3D%20kmem_cache_alloc(skbuff_head_cache%2C%20GFP_ATOMIC)%3B%0A%09if%20(!skb)%0A%09%09return%20NULL%3B%0A%0A%09size%20-%3D%20SKB_DATA_ALIGN(sizeof(struct%20skb_shared_info))%3B%0A%0A%09memset(skb%2C%200%2C%20offsetof(struct%20sk_buff%2C%20tail))%3B%0A%09skb-%3Etruesize%20%3D%20SKB_TRUESIZE(size)%3B%0A%09skb-%3Ehead_frag%20%3D%20frag_size%20!%3D%200%3B%0A%09atomic_set(%26skb-%3Eusers%2C%201)%3B%0A%09skb-%3Ehead%20%3D%20data%3B%0A%09skb-%3Edata%20%3D%20data%3B%0A%09skb_reset_tail_pointer(skb)%3B%0A%09skb-%3Eend%20%3D%20skb-%3Etail%20%2B%20size%3B%0A%23ifdef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb-%3Emac_header%20%3D%20~0U%3B%0A%09skb-%3Etransport_header%20%3D%20~0U%3B%0A%23endif%0A%0A%09%2F*%20make%20sure%20we%20initialize%20shinfo%20sequentially%20*%2F%0A%09shinfo%20%3D%20skb_shinfo(skb)%3B%0A%09memset(shinfo%2C%200%2C%20offsetof(struct%20skb_shared_info%2C%20dataref))%3B%0A%09atomic_set(%26shinfo-%3Edataref%2C%201)%3B%0A%09kmemcheck_annotate_variable(shinfo-%3Edestructor_arg)%3B%0A%0A%09return%20skb%3B%0A%7D%0AEXPORT_SYMBOL(build_skb)%3B%0A%0Astruct%20netdev_alloc_cache%20%7B%0A%09struct%20page_frag%09frag%3B%0A%09%2F*%20we%20maintain%20a%20pagecount%20bias%2C%20so%20that%20we%20dont%20dirty%20cache%20line%0A%09%20*%20containing%20page-%3E_count%20every%20time%20we%20allocate%20a%20fragment.%0A%09%20*%2F%0A%09unsigned%20int%09%09pagecnt_bias%3B%0A%7D%3B%0Astatic%20DEFINE_PER_CPU(struct%20netdev_alloc_cache%2C%20netdev_alloc_cache)%3B%0A%0Astatic%20void%20*__netdev_alloc_frag(unsigned%20int%20fragsz%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09struct%20netdev_alloc_cache%20*nc%3B%0A%09void%20*data%20%3D%20NULL%3B%0A%09int%20order%3B%0A%09unsigned%20long%20flags%3B%0A%0A%09local_irq_save(flags)%3B%0A%09nc%20%3D%20%26__get_cpu_var(netdev_alloc_cache)%3B%0A%09if%20(unlikely(!nc-%3Efrag.page))%20%7B%0Arefill%3A%0A%09%09for%20(order%20%3D%20NETDEV_FRAG_PAGE_MAX_ORDER%3B%20%3B)%20%7B%0A%09%09%09gfp_t%20gfp%20%3D%20gfp_mask%3B%0A%0A%09%09%09if%20(order)%0A%09%09%09%09gfp%20%7C%3D%20__GFP_COMP%20%7C%20__GFP_NOWARN%3B%0A%09%09%09nc-%3Efrag.page%20%3D%20alloc_pages(gfp%2C%20order)%3B%0A%09%09%09if%20(likely(nc-%3Efrag.page))%0A%09%09%09%09break%3B%0A%09%09%09if%20(--order%20%3C%200)%0A%09%09%09%09goto%20end%3B%0A%09%09%7D%0A%09%09nc-%3Efrag.size%20%3D%20PAGE_SIZE%20%3C%3C%20order%3B%0Arecycle%3A%0A%09%09atomic_set(%26nc-%3Efrag.page-%3E_count%2C%20NETDEV_PAGECNT_MAX_BIAS)%3B%0A%09%09nc-%3Epagecnt_bias%20%3D%20NETDEV_PAGECNT_MAX_BIAS%3B%0A%09%09nc-%3Efrag.offset%20%3D%200%3B%0A%09%7D%0A%0A%09if%20(nc-%3Efrag.offset%20%2B%20fragsz%20%3E%20nc-%3Efrag.size)%20%7B%0A%09%09%2F*%20avoid%20unnecessary%20locked%20operations%20if%20possible%20*%2F%0A%09%09if%20((atomic_read(%26nc-%3Efrag.page-%3E_count)%20%3D%3D%20nc-%3Epagecnt_bias)%20%7C%7C%0A%09%09%20%20%20%20atomic_sub_and_test(nc-%3Epagecnt_bias%2C%20%26nc-%3Efrag.page-%3E_count))%0A%09%09%09goto%20recycle%3B%0A%09%09goto%20refill%3B%0A%09%7D%0A%0A%09data%20%3D%20page_address(nc-%3Efrag.page)%20%2B%20nc-%3Efrag.offset%3B%0A%09nc-%3Efrag.offset%20%2B%3D%20fragsz%3B%0A%09nc-%3Epagecnt_bias--%3B%0Aend%3A%0A%09local_irq_restore(flags)%3B%0A%09return%20data%3B%0A%7D%0A%0A%2F**%0A%20*%20netdev_alloc_frag%20-%20allocate%20a%20page%20fragment%0A%20*%20%40fragsz%3A%20fragment%20size%0A%20*%0A%20*%20Allocates%20a%20frag%20from%20a%20page%20for%20receive%20buffer.%0A%20*%20Uses%20GFP_ATOMIC%20allocations.%0A%20*%2F%0Avoid%20*netdev_alloc_frag(unsigned%20int%20fragsz)%0A%7B%0A%09return%20__netdev_alloc_frag(fragsz%2C%20GFP_ATOMIC%20%7C%20__GFP_COLD)%3B%0A%7D%0AEXPORT_SYMBOL(netdev_alloc_frag)%3B%0A%0A%2F**%0A%20*%09__netdev_alloc_skb%20-%20allocate%20an%20skbuff%20for%20rx%20on%20a%20specific%20device%0A%20*%09%40dev%3A%20network%20device%20to%20receive%20on%0A%20*%09%40length%3A%20length%20to%20allocate%0A%20*%09%40gfp_mask%3A%20get_free_pages%20mask%2C%20passed%20to%20alloc_skb%0A%20*%0A%20*%09Allocate%20a%20new%20%26sk_buff%20and%20assign%20it%20a%20usage%20count%20of%20one.%20The%0A%20*%09buffer%20has%20unspecified%20headroom%20built%20in.%20Users%20should%20allocate%0A%20*%09the%20headroom%20they%20think%20they%20need%20without%20accounting%20for%20the%0A%20*%09built%20in%20space.%20The%20built%20in%20space%20is%20used%20for%20optimisations.%0A%20*%0A%20*%09%25NULL%20is%20returned%20if%20there%20is%20no%20free%20memory.%0A%20*%2F%0Astruct%20sk_buff%20*__netdev_alloc_skb(struct%20net_device%20*dev%2C%0A%09%09%09%09%20%20%20unsigned%20int%20length%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09struct%20sk_buff%20*skb%20%3D%20NULL%3B%0A%09unsigned%20int%20fragsz%20%3D%20SKB_DATA_ALIGN(length%20%2B%20NET_SKB_PAD)%20%2B%0A%09%09%09%20%20%20%20%20%20SKB_DATA_ALIGN(sizeof(struct%20skb_shared_info))%3B%0A%0A%09if%20(fragsz%20%3C%3D%20PAGE_SIZE%20%26%26%20!(gfp_mask%20%26%20(__GFP_WAIT%20%7C%20GFP_DMA)))%20%7B%0A%09%09void%20*data%3B%0A%0A%09%09if%20(sk_memalloc_socks())%0A%09%09%09gfp_mask%20%7C%3D%20__GFP_MEMALLOC%3B%0A%0A%09%09data%20%3D%20__netdev_alloc_frag(fragsz%2C%20gfp_mask)%3B%0A%0A%09%09if%20(likely(data))%20%7B%0A%09%09%09skb%20%3D%20build_skb(data%2C%20fragsz)%3B%0A%09%09%09if%20(unlikely(!skb))%0A%09%09%09%09put_page(virt_to_head_page(data))%3B%0A%09%09%7D%0A%09%7D%20else%20%7B%0A%09%09skb%20%3D%20__alloc_skb(length%20%2B%20NET_SKB_PAD%2C%20gfp_mask%2C%0A%09%09%09%09%20%20SKB_ALLOC_RX%2C%20NUMA_NO_NODE)%3B%0A%09%7D%0A%09if%20(likely(skb))%20%7B%0A%09%09skb_reserve(skb%2C%20NET_SKB_PAD)%3B%0A%09%09skb-%3Edev%20%3D%20dev%3B%0A%09%7D%0A%09return%20skb%3B%0A%7D%0AEXPORT_SYMBOL(__netdev_alloc_skb)%3B%0A%0Avoid%20skb_add_rx_frag(struct%20sk_buff%20*skb%2C%20int%20i%2C%20struct%20page%20*page%2C%20int%20off%2C%0A%09%09%20%20%20%20%20int%20size%2C%20unsigned%20int%20truesize)%0A%7B%0A%09skb_fill_page_desc(skb%2C%20i%2C%20page%2C%20off%2C%20size)%3B%0A%09skb-%3Elen%20%2B%3D%20size%3B%0A%09skb-%3Edata_len%20%2B%3D%20size%3B%0A%09skb-%3Etruesize%20%2B%3D%20truesize%3B%0A%7D%0AEXPORT_SYMBOL(skb_add_rx_frag)%3B%0A%0Astatic%20void%20skb_drop_list(struct%20sk_buff%20**listp)%0A%7B%0A%09kfree_skb_list(*listp)%3B%0A%09*listp%20%3D%20NULL%3B%0A%7D%0A%0Astatic%20inline%20void%20skb_drop_fraglist(struct%20sk_buff%20*skb)%0A%7B%0A%09skb_drop_list(%26skb_shinfo(skb)-%3Efrag_list)%3B%0A%7D%0A%0Astatic%20void%20skb_clone_fraglist(struct%20sk_buff%20*skb)%0A%7B%0A%09struct%20sk_buff%20*list%3B%0A%0A%09skb_walk_frags(skb%2C%20list)%0A%09%09skb_get(list)%3B%0A%7D%0A%0Astatic%20void%20skb_free_head(struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(skb-%3Ehead_frag)%0A%09%09put_page(virt_to_head_page(skb-%3Ehead))%3B%0A%09else%0A%09%09kfree(skb-%3Ehead)%3B%0A%7D%0A%0Astatic%20void%20skb_release_data(struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(!skb-%3Ecloned%20%7C%7C%0A%09%20%20%20%20!atomic_sub_return(skb-%3Enohdr%20%3F%20(1%20%3C%3C%20SKB_DATAREF_SHIFT)%20%2B%201%20%3A%201%2C%0A%09%09%09%20%20%20%20%20%20%20%26skb_shinfo(skb)-%3Edataref))%20%7B%0A%09%09if%20(skb_shinfo(skb)-%3Enr_frags)%20%7B%0A%09%09%09int%20i%3B%0A%09%09%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%0A%09%09%09%09skb_frag_unref(skb%2C%20i)%3B%0A%09%09%7D%0A%0A%09%09%2F*%0A%09%09%20*%20If%20skb%20buf%20is%20from%20userspace%2C%20we%20need%20to%20notify%20the%20caller%0A%09%09%20*%20the%20lower%20device%20DMA%20has%20done%3B%0A%09%09%20*%2F%0A%09%09if%20(skb_shinfo(skb)-%3Etx_flags%20%26%20SKBTX_DEV_ZEROCOPY)%20%7B%0A%09%09%09struct%20ubuf_info%20*uarg%3B%0A%0A%09%09%09uarg%20%3D%20skb_shinfo(skb)-%3Edestructor_arg%3B%0A%09%09%09if%20(uarg-%3Ecallback)%0A%09%09%09%09uarg-%3Ecallback(uarg%2C%20true)%3B%0A%09%09%7D%0A%0A%09%09if%20(skb_has_frag_list(skb))%0A%09%09%09skb_drop_fraglist(skb)%3B%0A%0A%09%09skb_free_head(skb)%3B%0A%09%7D%0A%7D%0A%0A%2F*%0A%20*%09Free%20an%20skbuff%20by%20memory%20without%20cleaning%20the%20state.%0A%20*%2F%0Astatic%20void%20kfree_skbmem(struct%20sk_buff%20*skb)%0A%7B%0A%09struct%20sk_buff%20*other%3B%0A%09atomic_t%20*fclone_ref%3B%0A%0A%09switch%20(skb-%3Efclone)%20%7B%0A%09case%20SKB_FCLONE_UNAVAILABLE%3A%0A%09%09kmem_cache_free(skbuff_head_cache%2C%20skb)%3B%0A%09%09break%3B%0A%0A%09case%20SKB_FCLONE_ORIG%3A%0A%09%09fclone_ref%20%3D%20(atomic_t%20*)%20(skb%20%2B%202)%3B%0A%09%09if%20(atomic_dec_and_test(fclone_ref))%0A%09%09%09kmem_cache_free(skbuff_fclone_cache%2C%20skb)%3B%0A%09%09break%3B%0A%0A%09case%20SKB_FCLONE_CLONE%3A%0A%09%09fclone_ref%20%3D%20(atomic_t%20*)%20(skb%20%2B%201)%3B%0A%09%09other%20%3D%20skb%20-%201%3B%0A%0A%09%09%2F*%20The%20clone%20portion%20is%20available%20for%0A%09%09%20*%20fast-cloning%20again.%0A%09%09%20*%2F%0A%09%09skb-%3Efclone%20%3D%20SKB_FCLONE_UNAVAILABLE%3B%0A%0A%09%09if%20(atomic_dec_and_test(fclone_ref))%0A%09%09%09kmem_cache_free(skbuff_fclone_cache%2C%20other)%3B%0A%09%09break%3B%0A%09%7D%0A%7D%0A%0Astatic%20void%20skb_release_head_state(struct%20sk_buff%20*skb)%0A%7B%0A%09skb_dst_drop(skb)%3B%0A%23ifdef%20CONFIG_XFRM%0A%09secpath_put(skb-%3Esp)%3B%0A%23endif%0A%09if%20(skb-%3Edestructor)%20%7B%0A%09%09WARN_ON(in_irq())%3B%0A%09%09skb-%3Edestructor(skb)%3B%0A%09%7D%0A%23if%20IS_ENABLED(CONFIG_NF_CONNTRACK)%0A%09nf_conntrack_put(skb-%3Enfct)%3B%0A%23endif%0A%23ifdef%20CONFIG_BRIDGE_NETFILTER%0A%09nf_bridge_put(skb-%3Enf_bridge)%3B%0A%23endif%0A%2F*%20XXX%3A%20IS%20this%20still%20necessary%3F%20-%20JHS%20*%2F%0A%23ifdef%20CONFIG_NET_SCHED%0A%09skb-%3Etc_index%20%3D%200%3B%0A%23ifdef%20CONFIG_NET_CLS_ACT%0A%09skb-%3Etc_verd%20%3D%200%3B%0A%23endif%0A%23endif%0A%7D%0A%0A%2F*%20Free%20everything%20but%20the%20sk_buff%20shell.%20*%2F%0Astatic%20void%20skb_release_all(struct%20sk_buff%20*skb)%0A%7B%0A%09skb_release_head_state(skb)%3B%0A%09if%20(likely(skb-%3Ehead))%0A%09%09skb_release_data(skb)%3B%0A%7D%0A%0A%2F**%0A%20*%09__kfree_skb%20-%20private%20function%0A%20*%09%40skb%3A%20buffer%0A%20*%0A%20*%09Free%20an%20sk_buff.%20Release%20anything%20attached%20to%20the%20buffer.%0A%20*%09Clean%20the%20state.%20This%20is%20an%20internal%20helper%20function.%20Users%20should%0A%20*%09always%20call%20kfree_skb%0A%20*%2F%0A%0Avoid%20__kfree_skb(struct%20sk_buff%20*skb)%0A%7B%0A%09skb_release_all(skb)%3B%0A%09kfree_skbmem(skb)%3B%0A%7D%0AEXPORT_SYMBOL(__kfree_skb)%3B%0A%0A%2F**%0A%20*%09kfree_skb%20-%20free%20an%20sk_buff%0A%20*%09%40skb%3A%20buffer%20to%20free%0A%20*%0A%20*%09Drop%20a%20reference%20to%20the%20buffer%20and%20free%20it%20if%20the%20usage%20count%20has%0A%20*%09hit%20zero.%0A%20*%2F%0Avoid%20kfree_skb(struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(unlikely(!skb))%0A%09%09return%3B%0A%09if%20(likely(atomic_read(%26skb-%3Eusers)%20%3D%3D%201))%0A%09%09smp_rmb()%3B%0A%09else%20if%20(likely(!atomic_dec_and_test(%26skb-%3Eusers)))%0A%09%09return%3B%0A%09trace_kfree_skb(skb%2C%20__builtin_return_address(0))%3B%0A%09__kfree_skb(skb)%3B%0A%7D%0AEXPORT_SYMBOL(kfree_skb)%3B%0A%0Avoid%20kfree_skb_list(struct%20sk_buff%20*segs)%0A%7B%0A%09while%20(segs)%20%7B%0A%09%09struct%20sk_buff%20*next%20%3D%20segs-%3Enext%3B%0A%0A%09%09kfree_skb(segs)%3B%0A%09%09segs%20%3D%20next%3B%0A%09%7D%0A%7D%0AEXPORT_SYMBOL(kfree_skb_list)%3B%0A%0A%2F**%0A%20*%09skb_tx_error%20-%20report%20an%20sk_buff%20xmit%20error%0A%20*%09%40skb%3A%20buffer%20that%20triggered%20an%20error%0A%20*%0A%20*%09Report%20xmit%20error%20if%20a%20device%20callback%20is%20tracking%20this%20skb.%0A%20*%09skb%20must%20be%20freed%20afterwards.%0A%20*%2F%0Avoid%20skb_tx_error(struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(skb_shinfo(skb)-%3Etx_flags%20%26%20SKBTX_DEV_ZEROCOPY)%20%7B%0A%09%09struct%20ubuf_info%20*uarg%3B%0A%0A%09%09uarg%20%3D%20skb_shinfo(skb)-%3Edestructor_arg%3B%0A%09%09if%20(uarg-%3Ecallback)%0A%09%09%09uarg-%3Ecallback(uarg%2C%20false)%3B%0A%09%09skb_shinfo(skb)-%3Etx_flags%20%26%3D%20~SKBTX_DEV_ZEROCOPY%3B%0A%09%7D%0A%7D%0AEXPORT_SYMBOL(skb_tx_error)%3B%0A%0A%2F**%0A%20*%09consume_skb%20-%20free%20an%20skbuff%0A%20*%09%40skb%3A%20buffer%20to%20free%0A%20*%0A%20*%09Drop%20a%20ref%20to%20the%20buffer%20and%20free%20it%20if%20the%20usage%20count%20has%20hit%20zero%0A%20*%09Functions%20identically%20to%20kfree_skb%2C%20but%20kfree_skb%20assumes%20that%20the%20frame%0A%20*%09is%20being%20dropped%20after%20a%20failure%20and%20notes%20that%0A%20*%2F%0Avoid%20consume_skb(struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(unlikely(!skb))%0A%09%09return%3B%0A%09if%20(likely(atomic_read(%26skb-%3Eusers)%20%3D%3D%201))%0A%09%09smp_rmb()%3B%0A%09else%20if%20(likely(!atomic_dec_and_test(%26skb-%3Eusers)))%0A%09%09return%3B%0A%09trace_consume_skb(skb)%3B%0A%09__kfree_skb(skb)%3B%0A%7D%0AEXPORT_SYMBOL(consume_skb)%3B%0A%0Astatic%20void%20__copy_skb_header(struct%20sk_buff%20*new%2C%20const%20struct%20sk_buff%20*old)%0A%7B%0A%09new-%3Etstamp%09%09%3D%20old-%3Etstamp%3B%0A%09new-%3Edev%09%09%3D%20old-%3Edev%3B%0A%09new-%3Etransport_header%09%3D%20old-%3Etransport_header%3B%0A%09new-%3Enetwork_header%09%3D%20old-%3Enetwork_header%3B%0A%09new-%3Emac_header%09%09%3D%20old-%3Emac_header%3B%0A%09new-%3Einner_transport_header%20%3D%20old-%3Einner_transport_header%3B%0A%09new-%3Einner_network_header%20%3D%20old-%3Einner_network_header%3B%0A%09new-%3Einner_mac_header%20%3D%20old-%3Einner_mac_header%3B%0A%09skb_dst_copy(new%2C%20old)%3B%0A%09new-%3Erxhash%09%09%3D%20old-%3Erxhash%3B%0A%09new-%3Eooo_okay%09%09%3D%20old-%3Eooo_okay%3B%0A%09new-%3El4_rxhash%09%09%3D%20old-%3El4_rxhash%3B%0A%09new-%3Eno_fcs%09%09%3D%20old-%3Eno_fcs%3B%0A%09new-%3Eencapsulation%09%3D%20old-%3Eencapsulation%3B%0A%23ifdef%20CONFIG_XFRM%0A%09new-%3Esp%09%09%09%3D%20secpath_get(old-%3Esp)%3B%0A%23endif%0A%09memcpy(new-%3Ecb%2C%20old-%3Ecb%2C%20sizeof(old-%3Ecb))%3B%0A%09new-%3Ecsum%09%09%3D%20old-%3Ecsum%3B%0A%09new-%3Elocal_df%09%09%3D%20old-%3Elocal_df%3B%0A%09new-%3Epkt_type%09%09%3D%20old-%3Epkt_type%3B%0A%09new-%3Eip_summed%09%09%3D%20old-%3Eip_summed%3B%0A%09skb_copy_queue_mapping(new%2C%20old)%3B%0A%09new-%3Epriority%09%09%3D%20old-%3Epriority%3B%0A%23if%20IS_ENABLED(CONFIG_IP_VS)%0A%09new-%3Eipvs_property%09%3D%20old-%3Eipvs_property%3B%0A%23endif%0A%09new-%3Epfmemalloc%09%09%3D%20old-%3Epfmemalloc%3B%0A%09new-%3Eprotocol%09%09%3D%20old-%3Eprotocol%3B%0A%09new-%3Emark%09%09%3D%20old-%3Emark%3B%0A%09new-%3Eskb_iif%09%09%3D%20old-%3Eskb_iif%3B%0A%09__nf_copy(new%2C%20old)%3B%0A%23if%20IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)%0A%09new-%3Enf_trace%09%09%3D%20old-%3Enf_trace%3B%0A%23endif%0A%23ifdef%20CONFIG_NET_SCHED%0A%09new-%3Etc_index%09%09%3D%20old-%3Etc_index%3B%0A%23ifdef%20CONFIG_NET_CLS_ACT%0A%09new-%3Etc_verd%09%09%3D%20old-%3Etc_verd%3B%0A%23endif%0A%23endif%0A%09new-%3Evlan_proto%09%09%3D%20old-%3Evlan_proto%3B%0A%09new-%3Evlan_tci%09%09%3D%20old-%3Evlan_tci%3B%0A%0A%09skb_copy_secmark(new%2C%20old)%3B%0A%7D%0A%0A%2F*%0A%20*%20You%20should%20not%20add%20any%20new%20code%20to%20this%20function.%20%20Add%20it%20to%0A%20*%20__copy_skb_header%20above%20instead.%0A%20*%2F%0Astatic%20struct%20sk_buff%20*__skb_clone(struct%20sk_buff%20*n%2C%20struct%20sk_buff%20*skb)%0A%7B%0A%23define%20C(x)%20n-%3Ex%20%3D%20skb-%3Ex%0A%0A%09n-%3Enext%20%3D%20n-%3Eprev%20%3D%20NULL%3B%0A%09n-%3Esk%20%3D%20NULL%3B%0A%09__copy_skb_header(n%2C%20skb)%3B%0A%0A%09C(len)%3B%0A%09C(data_len)%3B%0A%09C(mac_len)%3B%0A%09n-%3Ehdr_len%20%3D%20skb-%3Enohdr%20%3F%20skb_headroom(skb)%20%3A%20skb-%3Ehdr_len%3B%0A%09n-%3Ecloned%20%3D%201%3B%0A%09n-%3Enohdr%20%3D%200%3B%0A%09n-%3Edestructor%20%3D%20NULL%3B%0A%09C(tail)%3B%0A%09C(end)%3B%0A%09C(head)%3B%0A%09C(head_frag)%3B%0A%09C(data)%3B%0A%09C(truesize)%3B%0A%09atomic_set(%26n-%3Eusers%2C%201)%3B%0A%0A%09atomic_inc(%26(skb_shinfo(skb)-%3Edataref))%3B%0A%09skb-%3Ecloned%20%3D%201%3B%0A%0A%09return%20n%3B%0A%23undef%20C%0A%7D%0A%0A%2F**%0A%20*%09skb_morph%09-%09morph%20one%20skb%20into%20another%0A%20*%09%40dst%3A%20the%20skb%20to%20receive%20the%20contents%0A%20*%09%40src%3A%20the%20skb%20to%20supply%20the%20contents%0A%20*%0A%20*%09This%20is%20identical%20to%20skb_clone%20except%20that%20the%20target%20skb%20is%0A%20*%09supplied%20by%20the%20user.%0A%20*%0A%20*%09The%20target%20skb%20is%20returned%20upon%20exit.%0A%20*%2F%0Astruct%20sk_buff%20*skb_morph(struct%20sk_buff%20*dst%2C%20struct%20sk_buff%20*src)%0A%7B%0A%09skb_release_all(dst)%3B%0A%09return%20__skb_clone(dst%2C%20src)%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_morph)%3B%0A%0A%2F**%0A%20*%09skb_copy_ubufs%09-%09copy%20userspace%20skb%20frags%20buffers%20to%20kernel%0A%20*%09%40skb%3A%20the%20skb%20to%20modify%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09This%20must%20be%20called%20on%20SKBTX_DEV_ZEROCOPY%20skb.%0A%20*%09It%20will%20copy%20all%20frags%20into%20kernel%20and%20drop%20the%20reference%0A%20*%09to%20userspace%20pages.%0A%20*%0A%20*%09If%20this%20function%20is%20called%20from%20an%20interrupt%20gfp_mask()%20must%20be%0A%20*%09%25GFP_ATOMIC.%0A%20*%0A%20*%09Returns%200%20on%20success%20or%20a%20negative%20error%20code%20on%20failure%0A%20*%09to%20allocate%20kernel%20memory%20to%20copy%20to.%0A%20*%2F%0Aint%20skb_copy_ubufs(struct%20sk_buff%20*skb%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09int%20i%3B%0A%09int%20num_frags%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%09struct%20page%20*page%2C%20*head%20%3D%20NULL%3B%0A%09struct%20ubuf_info%20*uarg%20%3D%20skb_shinfo(skb)-%3Edestructor_arg%3B%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20num_frags%3B%20i%2B%2B)%20%7B%0A%09%09u8%20*vaddr%3B%0A%09%09skb_frag_t%20*f%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09page%20%3D%20alloc_page(gfp_mask)%3B%0A%09%09if%20(!page)%20%7B%0A%09%09%09while%20(head)%20%7B%0A%09%09%09%09struct%20page%20*next%20%3D%20(struct%20page%20*)head-%3Eprivate%3B%0A%09%09%09%09put_page(head)%3B%0A%09%09%09%09head%20%3D%20next%3B%0A%09%09%09%7D%0A%09%09%09return%20-ENOMEM%3B%0A%09%09%7D%0A%09%09vaddr%20%3D%20kmap_atomic(skb_frag_page(f))%3B%0A%09%09memcpy(page_address(page)%2C%0A%09%09%20%20%20%20%20%20%20vaddr%20%2B%20f-%3Epage_offset%2C%20skb_frag_size(f))%3B%0A%09%09kunmap_atomic(vaddr)%3B%0A%09%09page-%3Eprivate%20%3D%20(unsigned%20long)head%3B%0A%09%09head%20%3D%20page%3B%0A%09%7D%0A%0A%09%2F*%20skb%20frags%20release%20userspace%20buffers%20*%2F%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20num_frags%3B%20i%2B%2B)%0A%09%09skb_frag_unref(skb%2C%20i)%3B%0A%0A%09uarg-%3Ecallback(uarg%2C%20false)%3B%0A%0A%09%2F*%20skb%20frags%20point%20to%20kernel%20buffers%20*%2F%0A%09for%20(i%20%3D%20num_frags%20-%201%3B%20i%20%3E%3D%200%3B%20i--)%20%7B%0A%09%09__skb_fill_page_desc(skb%2C%20i%2C%20head%2C%200%2C%0A%09%09%09%09%20%20%20%20%20skb_shinfo(skb)-%3Efrags%5Bi%5D.size)%3B%0A%09%09head%20%3D%20(struct%20page%20*)head-%3Eprivate%3B%0A%09%7D%0A%0A%09skb_shinfo(skb)-%3Etx_flags%20%26%3D%20~SKBTX_DEV_ZEROCOPY%3B%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_copy_ubufs)%3B%0A%0A%2F**%0A%20*%09skb_clone%09-%09duplicate%20an%20sk_buff%0A%20*%09%40skb%3A%20buffer%20to%20clone%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09Duplicate%20an%20%26sk_buff.%20The%20new%20one%20is%20not%20owned%20by%20a%20socket.%20Both%0A%20*%09copies%20share%20the%20same%20packet%20data%20but%20not%20structure.%20The%20new%0A%20*%09buffer%20has%20a%20reference%20count%20of%201.%20If%20the%20allocation%20fails%20the%0A%20*%09function%20returns%20%25NULL%20otherwise%20the%20new%20buffer%20is%20returned.%0A%20*%0A%20*%09If%20this%20function%20is%20called%20from%20an%20interrupt%20gfp_mask()%20must%20be%0A%20*%09%25GFP_ATOMIC.%0A%20*%2F%0A%0Astruct%20sk_buff%20*skb_clone(struct%20sk_buff%20*skb%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09struct%20sk_buff%20*n%3B%0A%0A%09if%20(skb_orphan_frags(skb%2C%20gfp_mask))%0A%09%09return%20NULL%3B%0A%0A%09n%20%3D%20skb%20%2B%201%3B%0A%09if%20(skb-%3Efclone%20%3D%3D%20SKB_FCLONE_ORIG%20%26%26%0A%09%20%20%20%20n-%3Efclone%20%3D%3D%20SKB_FCLONE_UNAVAILABLE)%20%7B%0A%09%09atomic_t%20*fclone_ref%20%3D%20(atomic_t%20*)%20(n%20%2B%201)%3B%0A%09%09n-%3Efclone%20%3D%20SKB_FCLONE_CLONE%3B%0A%09%09atomic_inc(fclone_ref)%3B%0A%09%7D%20else%20%7B%0A%09%09if%20(skb_pfmemalloc(skb))%0A%09%09%09gfp_mask%20%7C%3D%20__GFP_MEMALLOC%3B%0A%0A%09%09n%20%3D%20kmem_cache_alloc(skbuff_head_cache%2C%20gfp_mask)%3B%0A%09%09if%20(!n)%0A%09%09%09return%20NULL%3B%0A%0A%09%09kmemcheck_annotate_bitfield(n%2C%20flags1)%3B%0A%09%09kmemcheck_annotate_bitfield(n%2C%20flags2)%3B%0A%09%09n-%3Efclone%20%3D%20SKB_FCLONE_UNAVAILABLE%3B%0A%09%7D%0A%0A%09return%20__skb_clone(n%2C%20skb)%3B%0A%7D%0AEXPORT_SYMBOL(skb_clone)%3B%0A%0Astatic%20void%20skb_headers_offset_update(struct%20sk_buff%20*skb%2C%20int%20off)%0A%7B%0A%09%2F*%20%7Btransport%2Cnetwork%2Cmac%7D_header%20and%20tail%20are%20relative%20to%20skb-%3Ehead%20*%2F%0A%09skb-%3Etransport_header%20%2B%3D%20off%3B%0A%09skb-%3Enetwork_header%20%20%20%2B%3D%20off%3B%0A%09if%20(skb_mac_header_was_set(skb))%0A%09%09skb-%3Emac_header%20%2B%3D%20off%3B%0A%09skb-%3Einner_transport_header%20%2B%3D%20off%3B%0A%09skb-%3Einner_network_header%20%2B%3D%20off%3B%0A%09skb-%3Einner_mac_header%20%2B%3D%20off%3B%0A%7D%0A%0Astatic%20void%20copy_skb_header(struct%20sk_buff%20*new%2C%20const%20struct%20sk_buff%20*old)%0A%7B%0A%23ifndef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09%2F*%0A%09%20*%09Shift%20between%20the%20two%20data%20areas%20in%20bytes%0A%09%20*%2F%0A%09unsigned%20long%20offset%20%3D%20new-%3Edata%20-%20old-%3Edata%3B%0A%23endif%0A%0A%09__copy_skb_header(new%2C%20old)%3B%0A%0A%23ifndef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb_headers_offset_update(new%2C%20offset)%3B%0A%23endif%0A%09skb_shinfo(new)-%3Egso_size%20%3D%20skb_shinfo(old)-%3Egso_size%3B%0A%09skb_shinfo(new)-%3Egso_segs%20%3D%20skb_shinfo(old)-%3Egso_segs%3B%0A%09skb_shinfo(new)-%3Egso_type%20%3D%20skb_shinfo(old)-%3Egso_type%3B%0A%7D%0A%0Astatic%20inline%20int%20skb_alloc_rx_flag(const%20struct%20sk_buff%20*skb)%0A%7B%0A%09if%20(skb_pfmemalloc(skb))%0A%09%09return%20SKB_ALLOC_RX%3B%0A%09return%200%3B%0A%7D%0A%0A%2F**%0A%20*%09skb_copy%09-%09create%20private%20copy%20of%20an%20sk_buff%0A%20*%09%40skb%3A%20buffer%20to%20copy%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09Make%20a%20copy%20of%20both%20an%20%26sk_buff%20and%20its%20data.%20This%20is%20used%20when%20the%0A%20*%09caller%20wishes%20to%20modify%20the%20data%20and%20needs%20a%20private%20copy%20of%20the%0A%20*%09data%20to%20alter.%20Returns%20%25NULL%20on%20failure%20or%20the%20pointer%20to%20the%20buffer%0A%20*%09on%20success.%20The%20returned%20buffer%20has%20a%20reference%20count%20of%201.%0A%20*%0A%20*%09As%20by-product%20this%20function%20converts%20non-linear%20%26sk_buff%20to%20linear%0A%20*%09one%2C%20so%20that%20%26sk_buff%20becomes%20completely%20private%20and%20caller%20is%20allowed%0A%20*%09to%20modify%20all%20the%20data%20of%20returned%20buffer.%20This%20means%20that%20this%0A%20*%09function%20is%20not%20recommended%20for%20use%20in%20circumstances%20when%20only%0A%20*%09header%20is%20going%20to%20be%20modified.%20Use%20pskb_copy()%20instead.%0A%20*%2F%0A%0Astruct%20sk_buff%20*skb_copy(const%20struct%20sk_buff%20*skb%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09int%20headerlen%20%3D%20skb_headroom(skb)%3B%0A%09unsigned%20int%20size%20%3D%20skb_end_offset(skb)%20%2B%20skb-%3Edata_len%3B%0A%09struct%20sk_buff%20*n%20%3D%20__alloc_skb(size%2C%20gfp_mask%2C%0A%09%09%09%09%09skb_alloc_rx_flag(skb)%2C%20NUMA_NO_NODE)%3B%0A%0A%09if%20(!n)%0A%09%09return%20NULL%3B%0A%0A%09%2F*%20Set%20the%20data%20pointer%20*%2F%0A%09skb_reserve(n%2C%20headerlen)%3B%0A%09%2F*%20Set%20the%20tail%20pointer%20and%20length%20*%2F%0A%09skb_put(n%2C%20skb-%3Elen)%3B%0A%0A%09if%20(skb_copy_bits(skb%2C%20-headerlen%2C%20n-%3Ehead%2C%20headerlen%20%2B%20skb-%3Elen))%0A%09%09BUG()%3B%0A%0A%09copy_skb_header(n%2C%20skb)%3B%0A%09return%20n%3B%0A%7D%0AEXPORT_SYMBOL(skb_copy)%3B%0A%0A%2F**%0A%20*%09__pskb_copy%09-%09create%20copy%20of%20an%20sk_buff%20with%20private%20head.%0A%20*%09%40skb%3A%20buffer%20to%20copy%0A%20*%09%40headroom%3A%20headroom%20of%20new%20skb%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09Make%20a%20copy%20of%20both%20an%20%26sk_buff%20and%20part%20of%20its%20data%2C%20located%0A%20*%09in%20header.%20Fragmented%20data%20remain%20shared.%20This%20is%20used%20when%0A%20*%09the%20caller%20wishes%20to%20modify%20only%20header%20of%20%26sk_buff%20and%20needs%0A%20*%09private%20copy%20of%20the%20header%20to%20alter.%20Returns%20%25NULL%20on%20failure%0A%20*%09or%20the%20pointer%20to%20the%20buffer%20on%20success.%0A%20*%09The%20returned%20buffer%20has%20a%20reference%20count%20of%201.%0A%20*%2F%0A%0Astruct%20sk_buff%20*__pskb_copy(struct%20sk_buff%20*skb%2C%20int%20headroom%2C%20gfp_t%20gfp_mask)%0A%7B%0A%09unsigned%20int%20size%20%3D%20skb_headlen(skb)%20%2B%20headroom%3B%0A%09struct%20sk_buff%20*n%20%3D%20__alloc_skb(size%2C%20gfp_mask%2C%0A%09%09%09%09%09skb_alloc_rx_flag(skb)%2C%20NUMA_NO_NODE)%3B%0A%0A%09if%20(!n)%0A%09%09goto%20out%3B%0A%0A%09%2F*%20Set%20the%20data%20pointer%20*%2F%0A%09skb_reserve(n%2C%20headroom)%3B%0A%09%2F*%20Set%20the%20tail%20pointer%20and%20length%20*%2F%0A%09skb_put(n%2C%20skb_headlen(skb))%3B%0A%09%2F*%20Copy%20the%20bytes%20*%2F%0A%09skb_copy_from_linear_data(skb%2C%20n-%3Edata%2C%20n-%3Elen)%3B%0A%0A%09n-%3Etruesize%20%2B%3D%20skb-%3Edata_len%3B%0A%09n-%3Edata_len%20%20%3D%20skb-%3Edata_len%3B%0A%09n-%3Elen%09%20%20%20%20%20%3D%20skb-%3Elen%3B%0A%0A%09if%20(skb_shinfo(skb)-%3Enr_frags)%20%7B%0A%09%09int%20i%3B%0A%0A%09%09if%20(skb_orphan_frags(skb%2C%20gfp_mask))%20%7B%0A%09%09%09kfree_skb(n)%3B%0A%09%09%09n%20%3D%20NULL%3B%0A%09%09%09goto%20out%3B%0A%09%09%7D%0A%09%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09%09skb_shinfo(n)-%3Efrags%5Bi%5D%20%3D%20skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%09%09%09skb_frag_ref(skb%2C%20i)%3B%0A%09%09%7D%0A%09%09skb_shinfo(n)-%3Enr_frags%20%3D%20i%3B%0A%09%7D%0A%0A%09if%20(skb_has_frag_list(skb))%20%7B%0A%09%09skb_shinfo(n)-%3Efrag_list%20%3D%20skb_shinfo(skb)-%3Efrag_list%3B%0A%09%09skb_clone_fraglist(n)%3B%0A%09%7D%0A%0A%09copy_skb_header(n%2C%20skb)%3B%0Aout%3A%0A%09return%20n%3B%0A%7D%0AEXPORT_SYMBOL(__pskb_copy)%3B%0A%0A%2F**%0A%20*%09pskb_expand_head%20-%20reallocate%20header%20of%20%26sk_buff%0A%20*%09%40skb%3A%20buffer%20to%20reallocate%0A%20*%09%40nhead%3A%20room%20to%20add%20at%20head%0A%20*%09%40ntail%3A%20room%20to%20add%20at%20tail%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09Expands%20(or%20creates%20identical%20copy%2C%20if%20%26nhead%20and%20%26ntail%20are%20zero)%0A%20*%09header%20of%20skb.%20%26sk_buff%20itself%20is%20not%20changed.%20%26sk_buff%20MUST%20have%0A%20*%09reference%20count%20of%201.%20Returns%20zero%20in%20the%20case%20of%20success%20or%20error%2C%0A%20*%09if%20expansion%20failed.%20In%20the%20last%20case%2C%20%26sk_buff%20is%20not%20changed.%0A%20*%0A%20*%09All%20the%20pointers%20pointing%20into%20skb%20header%20may%20change%20and%20must%20be%0A%20*%09reloaded%20after%20call%20to%20this%20function.%0A%20*%2F%0A%0Aint%20pskb_expand_head(struct%20sk_buff%20*skb%2C%20int%20nhead%2C%20int%20ntail%2C%0A%09%09%20%20%20%20%20gfp_t%20gfp_mask)%0A%7B%0A%09int%20i%3B%0A%09u8%20*data%3B%0A%09int%20size%20%3D%20nhead%20%2B%20skb_end_offset(skb)%20%2B%20ntail%3B%0A%09long%20off%3B%0A%0A%09BUG_ON(nhead%20%3C%200)%3B%0A%0A%09if%20(skb_shared(skb))%0A%09%09BUG()%3B%0A%0A%09size%20%3D%20SKB_DATA_ALIGN(size)%3B%0A%0A%09if%20(skb_pfmemalloc(skb))%0A%09%09gfp_mask%20%7C%3D%20__GFP_MEMALLOC%3B%0A%09data%20%3D%20kmalloc_reserve(size%20%2B%20SKB_DATA_ALIGN(sizeof(struct%20skb_shared_info))%2C%0A%09%09%09%20%20%20%20%20%20%20gfp_mask%2C%20NUMA_NO_NODE%2C%20NULL)%3B%0A%09if%20(!data)%0A%09%09goto%20nodata%3B%0A%09size%20%3D%20SKB_WITH_OVERHEAD(ksize(data))%3B%0A%0A%09%2F*%20Copy%20only%20real%20data...%20and%2C%20alas%2C%20header.%20This%20should%20be%0A%09%20*%20optimized%20for%20the%20cases%20when%20header%20is%20void.%0A%09%20*%2F%0A%09memcpy(data%20%2B%20nhead%2C%20skb-%3Ehead%2C%20skb_tail_pointer(skb)%20-%20skb-%3Ehead)%3B%0A%0A%09memcpy((struct%20skb_shared_info%20*)(data%20%2B%20size)%2C%0A%09%20%20%20%20%20%20%20skb_shinfo(skb)%2C%0A%09%20%20%20%20%20%20%20offsetof(struct%20skb_shared_info%2C%20frags%5Bskb_shinfo(skb)-%3Enr_frags%5D))%3B%0A%0A%09%2F*%0A%09%20*%20if%20shinfo%20is%20shared%20we%20must%20drop%20the%20old%20head%20gracefully%2C%20but%20if%20it%0A%09%20*%20is%20not%20we%20can%20just%20drop%20the%20old%20head%20and%20let%20the%20existing%20refcount%0A%09%20*%20be%20since%20all%20we%20did%20is%20relocate%20the%20values%0A%09%20*%2F%0A%09if%20(skb_cloned(skb))%20%7B%0A%09%09%2F*%20copy%20this%20zero%20copy%20skb%20frags%20*%2F%0A%09%09if%20(skb_orphan_frags(skb%2C%20gfp_mask))%0A%09%09%09goto%20nofrags%3B%0A%09%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%0A%09%09%09skb_frag_ref(skb%2C%20i)%3B%0A%0A%09%09if%20(skb_has_frag_list(skb))%0A%09%09%09skb_clone_fraglist(skb)%3B%0A%0A%09%09skb_release_data(skb)%3B%0A%09%7D%20else%20%7B%0A%09%09skb_free_head(skb)%3B%0A%09%7D%0A%09off%20%3D%20(data%20%2B%20nhead)%20-%20skb-%3Ehead%3B%0A%0A%09skb-%3Ehead%20%20%20%20%20%3D%20data%3B%0A%09skb-%3Ehead_frag%20%3D%200%3B%0A%09skb-%3Edata%20%20%20%20%2B%3D%20off%3B%0A%23ifdef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb-%3Eend%20%20%20%20%20%20%3D%20size%3B%0A%09off%20%20%20%20%20%20%20%20%20%20%20%3D%20nhead%3B%0A%23else%0A%09skb-%3Eend%20%20%20%20%20%20%3D%20skb-%3Ehead%20%2B%20size%3B%0A%23endif%0A%09skb-%3Etail%09%20%20%20%20%20%20%2B%3D%20off%3B%0A%09skb_headers_offset_update(skb%2C%20off)%3B%0A%09%2F*%20Only%20adjust%20this%20if%20it%20actually%20is%20csum_start%20rather%20than%20csum%20*%2F%0A%09if%20(skb-%3Eip_summed%20%3D%3D%20CHECKSUM_PARTIAL)%0A%09%09skb-%3Ecsum_start%20%2B%3D%20nhead%3B%0A%09skb-%3Ecloned%20%20%20%3D%200%3B%0A%09skb-%3Ehdr_len%20%20%3D%200%3B%0A%09skb-%3Enohdr%20%20%20%20%3D%200%3B%0A%09atomic_set(%26skb_shinfo(skb)-%3Edataref%2C%201)%3B%0A%09return%200%3B%0A%0Anofrags%3A%0A%09kfree(data)%3B%0Anodata%3A%0A%09return%20-ENOMEM%3B%0A%7D%0AEXPORT_SYMBOL(pskb_expand_head)%3B%0A%0A%2F*%20Make%20private%20copy%20of%20skb%20with%20writable%20head%20and%20some%20headroom%20*%2F%0A%0Astruct%20sk_buff%20*skb_realloc_headroom(struct%20sk_buff%20*skb%2C%20unsigned%20int%20headroom)%0A%7B%0A%09struct%20sk_buff%20*skb2%3B%0A%09int%20delta%20%3D%20headroom%20-%20skb_headroom(skb)%3B%0A%0A%09if%20(delta%20%3C%3D%200)%0A%09%09skb2%20%3D%20pskb_copy(skb%2C%20GFP_ATOMIC)%3B%0A%09else%20%7B%0A%09%09skb2%20%3D%20skb_clone(skb%2C%20GFP_ATOMIC)%3B%0A%09%09if%20(skb2%20%26%26%20pskb_expand_head(skb2%2C%20SKB_DATA_ALIGN(delta)%2C%200%2C%0A%09%09%09%09%09%20%20%20%20%20GFP_ATOMIC))%20%7B%0A%09%09%09kfree_skb(skb2)%3B%0A%09%09%09skb2%20%3D%20NULL%3B%0A%09%09%7D%0A%09%7D%0A%09return%20skb2%3B%0A%7D%0AEXPORT_SYMBOL(skb_realloc_headroom)%3B%0A%0A%2F**%0A%20*%09skb_copy_expand%09-%09copy%20and%20expand%20sk_buff%0A%20*%09%40skb%3A%20buffer%20to%20copy%0A%20*%09%40newheadroom%3A%20new%20free%20bytes%20at%20head%0A%20*%09%40newtailroom%3A%20new%20free%20bytes%20at%20tail%0A%20*%09%40gfp_mask%3A%20allocation%20priority%0A%20*%0A%20*%09Make%20a%20copy%20of%20both%20an%20%26sk_buff%20and%20its%20data%20and%20while%20doing%20so%0A%20*%09allocate%20additional%20space.%0A%20*%0A%20*%09This%20is%20used%20when%20the%20caller%20wishes%20to%20modify%20the%20data%20and%20needs%20a%0A%20*%09private%20copy%20of%20the%20data%20to%20alter%20as%20well%20as%20more%20space%20for%20new%20fields.%0A%20*%09Returns%20%25NULL%20on%20failure%20or%20the%20pointer%20to%20the%20buffer%0A%20*%09on%20success.%20The%20returned%20buffer%20has%20a%20reference%20count%20of%201.%0A%20*%0A%20*%09You%20must%20pass%20%25GFP_ATOMIC%20as%20the%20allocation%20priority%20if%20this%20function%0A%20*%09is%20called%20from%20an%20interrupt.%0A%20*%2F%0Astruct%20sk_buff%20*skb_copy_expand(const%20struct%20sk_buff%20*skb%2C%0A%09%09%09%09int%20newheadroom%2C%20int%20newtailroom%2C%0A%09%09%09%09gfp_t%20gfp_mask)%0A%7B%0A%09%2F*%0A%09%20*%09Allocate%20the%20copy%20buffer%0A%09%20*%2F%0A%09struct%20sk_buff%20*n%20%3D%20__alloc_skb(newheadroom%20%2B%20skb-%3Elen%20%2B%20newtailroom%2C%0A%09%09%09%09%09gfp_mask%2C%20skb_alloc_rx_flag(skb)%2C%0A%09%09%09%09%09NUMA_NO_NODE)%3B%0A%09int%20oldheadroom%20%3D%20skb_headroom(skb)%3B%0A%09int%20head_copy_len%2C%20head_copy_off%3B%0A%09int%20off%3B%0A%0A%09if%20(!n)%0A%09%09return%20NULL%3B%0A%0A%09skb_reserve(n%2C%20newheadroom)%3B%0A%0A%09%2F*%20Set%20the%20tail%20pointer%20and%20length%20*%2F%0A%09skb_put(n%2C%20skb-%3Elen)%3B%0A%0A%09head_copy_len%20%3D%20oldheadroom%3B%0A%09head_copy_off%20%3D%200%3B%0A%09if%20(newheadroom%20%3C%3D%20head_copy_len)%0A%09%09head_copy_len%20%3D%20newheadroom%3B%0A%09else%0A%09%09head_copy_off%20%3D%20newheadroom%20-%20head_copy_len%3B%0A%0A%09%2F*%20Copy%20the%20linear%20header%20and%20data.%20*%2F%0A%09if%20(skb_copy_bits(skb%2C%20-head_copy_len%2C%20n-%3Ehead%20%2B%20head_copy_off%2C%0A%09%09%09%20%20skb-%3Elen%20%2B%20head_copy_len))%0A%09%09BUG()%3B%0A%0A%09copy_skb_header(n%2C%20skb)%3B%0A%0A%09off%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%20newheadroom%20-%20oldheadroom%3B%0A%09if%20(n-%3Eip_summed%20%3D%3D%20CHECKSUM_PARTIAL)%0A%09%09n-%3Ecsum_start%20%2B%3D%20off%3B%0A%23ifdef%20NET_SKBUFF_DATA_USES_OFFSET%0A%09skb_headers_offset_update(n%2C%20off)%3B%0A%23endif%0A%0A%09return%20n%3B%0A%7D%0AEXPORT_SYMBOL(skb_copy_expand)%3B%0A%0A%2F**%0A%20*%09skb_pad%09%09%09-%09zero%20pad%20the%20tail%20of%20an%20skb%0A%20*%09%40skb%3A%20buffer%20to%20pad%0A%20*%09%40pad%3A%20space%20to%20pad%0A%20*%0A%20*%09Ensure%20that%20a%20buffer%20is%20followed%20by%20a%20padding%20area%20that%20is%20zero%0A%20*%09filled.%20Used%20by%20network%20drivers%20which%20may%20DMA%20or%20transfer%20data%0A%20*%09beyond%20the%20buffer%20end%20onto%20the%20wire.%0A%20*%0A%20*%09May%20return%20error%20in%20out%20of%20memory%20cases.%20The%20skb%20is%20freed%20on%20error.%0A%20*%2F%0A%0Aint%20skb_pad(struct%20sk_buff%20*skb%2C%20int%20pad)%0A%7B%0A%09int%20err%3B%0A%09int%20ntail%3B%0A%0A%09%2F*%20If%20the%20skbuff%20is%20non%20linear%20tailroom%20is%20always%20zero..%20*%2F%0A%09if%20(!skb_cloned(skb)%20%26%26%20skb_tailroom(skb)%20%3E%3D%20pad)%20%7B%0A%09%09memset(skb-%3Edata%2Bskb-%3Elen%2C%200%2C%20pad)%3B%0A%09%09return%200%3B%0A%09%7D%0A%0A%09ntail%20%3D%20skb-%3Edata_len%20%2B%20pad%20-%20(skb-%3Eend%20-%20skb-%3Etail)%3B%0A%09if%20(likely(skb_cloned(skb)%20%7C%7C%20ntail%20%3E%200))%20%7B%0A%09%09err%20%3D%20pskb_expand_head(skb%2C%200%2C%20ntail%2C%20GFP_ATOMIC)%3B%0A%09%09if%20(unlikely(err))%0A%09%09%09goto%20free_skb%3B%0A%09%7D%0A%0A%09%2F*%20FIXME%3A%20The%20use%20of%20this%20function%20with%20non-linear%20skb's%20really%20needs%0A%09%20*%20to%20be%20audited.%0A%09%20*%2F%0A%09err%20%3D%20skb_linearize(skb)%3B%0A%09if%20(unlikely(err))%0A%09%09goto%20free_skb%3B%0A%0A%09memset(skb-%3Edata%20%2B%20skb-%3Elen%2C%200%2C%20pad)%3B%0A%09return%200%3B%0A%0Afree_skb%3A%0A%09kfree_skb(skb)%3B%0A%09return%20err%3B%0A%7D%0AEXPORT_SYMBOL(skb_pad)%3B%0A%0A%2F**%0A%20*%09skb_put%20-%20add%20data%20to%20a%20buffer%0A%20*%09%40skb%3A%20buffer%20to%20use%0A%20*%09%40len%3A%20amount%20of%20data%20to%20add%0A%20*%0A%20*%09This%20function%20extends%20the%20used%20data%20area%20of%20the%20buffer.%20If%20this%20would%0A%20*%09exceed%20the%20total%20buffer%20size%20the%20kernel%20will%20panic.%20A%20pointer%20to%20the%0A%20*%09first%20byte%20of%20the%20extra%20data%20is%20returned.%0A%20*%2F%0Aunsigned%20char%20*skb_put(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09unsigned%20char%20*tmp%20%3D%20skb_tail_pointer(skb)%3B%0A%09SKB_LINEAR_ASSERT(skb)%3B%0A%09skb-%3Etail%20%2B%3D%20len%3B%0A%09skb-%3Elen%20%20%2B%3D%20len%3B%0A%09if%20(unlikely(skb-%3Etail%20%3E%20skb-%3Eend))%0A%09%09skb_over_panic(skb%2C%20len%2C%20__builtin_return_address(0))%3B%0A%09return%20tmp%3B%0A%7D%0AEXPORT_SYMBOL(skb_put)%3B%0A%0A%2F**%0A%20*%09skb_push%20-%20add%20data%20to%20the%20start%20of%20a%20buffer%0A%20*%09%40skb%3A%20buffer%20to%20use%0A%20*%09%40len%3A%20amount%20of%20data%20to%20add%0A%20*%0A%20*%09This%20function%20extends%20the%20used%20data%20area%20of%20the%20buffer%20at%20the%20buffer%0A%20*%09start.%20If%20this%20would%20exceed%20the%20total%20buffer%20headroom%20the%20kernel%20will%0A%20*%09panic.%20A%20pointer%20to%20the%20first%20byte%20of%20the%20extra%20data%20is%20returned.%0A%20*%2F%0Aunsigned%20char%20*skb_push(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09skb-%3Edata%20-%3D%20len%3B%0A%09skb-%3Elen%20%20%2B%3D%20len%3B%0A%09if%20(unlikely(skb-%3Edata%3Cskb-%3Ehead))%0A%09%09skb_under_panic(skb%2C%20len%2C%20__builtin_return_address(0))%3B%0A%09return%20skb-%3Edata%3B%0A%7D%0AEXPORT_SYMBOL(skb_push)%3B%0A%0A%2F**%0A%20*%09skb_pull%20-%20remove%20data%20from%20the%20start%20of%20a%20buffer%0A%20*%09%40skb%3A%20buffer%20to%20use%0A%20*%09%40len%3A%20amount%20of%20data%20to%20remove%0A%20*%0A%20*%09This%20function%20removes%20data%20from%20the%20start%20of%20a%20buffer%2C%20returning%0A%20*%09the%20memory%20to%20the%20headroom.%20A%20pointer%20to%20the%20next%20data%20in%20the%20buffer%0A%20*%09is%20returned.%20Once%20the%20data%20has%20been%20pulled%20future%20pushes%20will%20overwrite%0A%20*%09the%20old%20data.%0A%20*%2F%0Aunsigned%20char%20*skb_pull(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09return%20skb_pull_inline(skb%2C%20len)%3B%0A%7D%0AEXPORT_SYMBOL(skb_pull)%3B%0A%0A%2F**%0A%20*%09skb_trim%20-%20remove%20end%20from%20a%20buffer%0A%20*%09%40skb%3A%20buffer%20to%20alter%0A%20*%09%40len%3A%20new%20length%0A%20*%0A%20*%09Cut%20the%20length%20of%20a%20buffer%20down%20by%20removing%20data%20from%20the%20tail.%20If%0A%20*%09the%20buffer%20is%20already%20under%20the%20length%20specified%20it%20is%20not%20modified.%0A%20*%09The%20skb%20must%20be%20linear.%0A%20*%2F%0Avoid%20skb_trim(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09if%20(skb-%3Elen%20%3E%20len)%0A%09%09__skb_trim(skb%2C%20len)%3B%0A%7D%0AEXPORT_SYMBOL(skb_trim)%3B%0A%0A%2F*%20Trims%20skb%20to%20length%20len.%20It%20can%20change%20skb%20pointers.%0A%20*%2F%0A%0Aint%20___pskb_trim(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09struct%20sk_buff%20**fragp%3B%0A%09struct%20sk_buff%20*frag%3B%0A%09int%20offset%20%3D%20skb_headlen(skb)%3B%0A%09int%20nfrags%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%09int%20i%3B%0A%09int%20err%3B%0A%0A%09if%20(skb_cloned(skb)%20%26%26%0A%09%20%20%20%20unlikely((err%20%3D%20pskb_expand_head(skb%2C%200%2C%200%2C%20GFP_ATOMIC))))%0A%09%09return%20err%3B%0A%0A%09i%20%3D%200%3B%0A%09if%20(offset%20%3E%3D%20len)%0A%09%09goto%20drop_pages%3B%0A%0A%09for%20(%3B%20i%20%3C%20nfrags%3B%20i%2B%2B)%20%7B%0A%09%09int%20end%20%3D%20offset%20%2B%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%0A%09%09if%20(end%20%3C%20len)%20%7B%0A%09%09%09offset%20%3D%20end%3B%0A%09%09%09continue%3B%0A%09%09%7D%0A%0A%09%09skb_frag_size_set(%26skb_shinfo(skb)-%3Efrags%5Bi%2B%2B%5D%2C%20len%20-%20offset)%3B%0A%0Adrop_pages%3A%0A%09%09skb_shinfo(skb)-%3Enr_frags%20%3D%20i%3B%0A%0A%09%09for%20(%3B%20i%20%3C%20nfrags%3B%20i%2B%2B)%0A%09%09%09skb_frag_unref(skb%2C%20i)%3B%0A%0A%09%09if%20(skb_has_frag_list(skb))%0A%09%09%09skb_drop_fraglist(skb)%3B%0A%09%09goto%20done%3B%0A%09%7D%0A%0A%09for%20(fragp%20%3D%20%26skb_shinfo(skb)-%3Efrag_list%3B%20(frag%20%3D%20*fragp)%3B%0A%09%20%20%20%20%20fragp%20%3D%20%26frag-%3Enext)%20%7B%0A%09%09int%20end%20%3D%20offset%20%2B%20frag-%3Elen%3B%0A%0A%09%09if%20(skb_shared(frag))%20%7B%0A%09%09%09struct%20sk_buff%20*nfrag%3B%0A%0A%09%09%09nfrag%20%3D%20skb_clone(frag%2C%20GFP_ATOMIC)%3B%0A%09%09%09if%20(unlikely(!nfrag))%0A%09%09%09%09return%20-ENOMEM%3B%0A%0A%09%09%09nfrag-%3Enext%20%3D%20frag-%3Enext%3B%0A%09%09%09consume_skb(frag)%3B%0A%09%09%09frag%20%3D%20nfrag%3B%0A%09%09%09*fragp%20%3D%20frag%3B%0A%09%09%7D%0A%0A%09%09if%20(end%20%3C%20len)%20%7B%0A%09%09%09offset%20%3D%20end%3B%0A%09%09%09continue%3B%0A%09%09%7D%0A%0A%09%09if%20(end%20%3E%20len%20%26%26%0A%09%09%20%20%20%20unlikely((err%20%3D%20pskb_trim(frag%2C%20len%20-%20offset))))%0A%09%09%09return%20err%3B%0A%0A%09%09if%20(frag-%3Enext)%0A%09%09%09skb_drop_list(%26frag-%3Enext)%3B%0A%09%09break%3B%0A%09%7D%0A%0Adone%3A%0A%09if%20(len%20%3E%20skb_headlen(skb))%20%7B%0A%09%09skb-%3Edata_len%20-%3D%20skb-%3Elen%20-%20len%3B%0A%09%09skb-%3Elen%20%20%20%20%20%20%20%3D%20len%3B%0A%09%7D%20else%20%7B%0A%09%09skb-%3Elen%20%20%20%20%20%20%20%3D%20len%3B%0A%09%09skb-%3Edata_len%20%20%3D%200%3B%0A%09%09skb_set_tail_pointer(skb%2C%20len)%3B%0A%09%7D%0A%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL(___pskb_trim)%3B%0A%0A%2F**%0A%20*%09__pskb_pull_tail%20-%20advance%20tail%20of%20skb%20header%0A%20*%09%40skb%3A%20buffer%20to%20reallocate%0A%20*%09%40delta%3A%20number%20of%20bytes%20to%20advance%20tail%0A%20*%0A%20*%09The%20function%20makes%20a%20sense%20only%20on%20a%20fragmented%20%26sk_buff%2C%0A%20*%09it%20expands%20header%20moving%20its%20tail%20forward%20and%20copying%20necessary%0A%20*%09data%20from%20fragmented%20part.%0A%20*%0A%20*%09%26sk_buff%20MUST%20have%20reference%20count%20of%201.%0A%20*%0A%20*%09Returns%20%25NULL%20(and%20%26sk_buff%20does%20not%20change)%20if%20pull%20failed%0A%20*%09or%20value%20of%20new%20tail%20of%20skb%20in%20the%20case%20of%20success.%0A%20*%0A%20*%09All%20the%20pointers%20pointing%20into%20skb%20header%20may%20change%20and%20must%20be%0A%20*%09reloaded%20after%20call%20to%20this%20function.%0A%20*%2F%0A%0A%2F*%20Moves%20tail%20of%20skb%20head%20forward%2C%20copying%20data%20from%20fragmented%20part%2C%0A%20*%20when%20it%20is%20necessary.%0A%20*%201.%20It%20may%20fail%20due%20to%20malloc%20failure.%0A%20*%202.%20It%20may%20change%20skb%20pointers.%0A%20*%0A%20*%20It%20is%20pretty%20complicated.%20Luckily%2C%20it%20is%20called%20only%20in%20exceptional%20cases.%0A%20*%2F%0Aunsigned%20char%20*__pskb_pull_tail(struct%20sk_buff%20*skb%2C%20int%20delta)%0A%7B%0A%09%2F*%20If%20skb%20has%20not%20enough%20free%20space%20at%20tail%2C%20get%20new%20one%0A%09%20*%20plus%20128%20bytes%20for%20future%20expansions.%20If%20we%20have%20enough%0A%09%20*%20room%20at%20tail%2C%20reallocate%20without%20expansion%20only%20if%20skb%20is%20cloned.%0A%09%20*%2F%0A%09int%20i%2C%20k%2C%20eat%20%3D%20(skb-%3Etail%20%2B%20delta)%20-%20skb-%3Eend%3B%0A%0A%09if%20(eat%20%3E%200%20%7C%7C%20skb_cloned(skb))%20%7B%0A%09%09if%20(pskb_expand_head(skb%2C%200%2C%20eat%20%3E%200%20%3F%20eat%20%2B%20128%20%3A%200%2C%0A%09%09%09%09%20%20%20%20%20GFP_ATOMIC))%0A%09%09%09return%20NULL%3B%0A%09%7D%0A%0A%09if%20(skb_copy_bits(skb%2C%20skb_headlen(skb)%2C%20skb_tail_pointer(skb)%2C%20delta))%0A%09%09BUG()%3B%0A%0A%09%2F*%20Optimization%3A%20no%20fragments%2C%20no%20reasons%20to%20preestimate%0A%09%20*%20size%20of%20pulled%20pages.%20Superb.%0A%09%20*%2F%0A%09if%20(!skb_has_frag_list(skb))%0A%09%09goto%20pull_pages%3B%0A%0A%09%2F*%20Estimate%20size%20of%20pulled%20pages.%20*%2F%0A%09eat%20%3D%20delta%3B%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20size%20%3D%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%0A%09%09if%20(size%20%3E%3D%20eat)%0A%09%09%09goto%20pull_pages%3B%0A%09%09eat%20-%3D%20size%3B%0A%09%7D%0A%0A%09%2F*%20If%20we%20need%20update%20frag%20list%2C%20we%20are%20in%20troubles.%0A%09%20*%20Certainly%2C%20it%20possible%20to%20add%20an%20offset%20to%20skb%20data%2C%0A%09%20*%20but%20taking%20into%20account%20that%20pulling%20is%20expected%20to%0A%09%20*%20be%20very%20rare%20operation%2C%20it%20is%20worth%20to%20fight%20against%0A%09%20*%20further%20bloating%20skb%20head%20and%20crucify%20ourselves%20here%20instead.%0A%09%20*%20Pure%20masohism%2C%20indeed.%208)8)%0A%09%20*%2F%0A%09if%20(eat)%20%7B%0A%09%09struct%20sk_buff%20*list%20%3D%20skb_shinfo(skb)-%3Efrag_list%3B%0A%09%09struct%20sk_buff%20*clone%20%3D%20NULL%3B%0A%09%09struct%20sk_buff%20*insp%20%3D%20NULL%3B%0A%0A%09%09do%20%7B%0A%09%09%09BUG_ON(!list)%3B%0A%0A%09%09%09if%20(list-%3Elen%20%3C%3D%20eat)%20%7B%0A%09%09%09%09%2F*%20Eaten%20as%20whole.%20*%2F%0A%09%09%09%09eat%20-%3D%20list-%3Elen%3B%0A%09%09%09%09list%20%3D%20list-%3Enext%3B%0A%09%09%09%09insp%20%3D%20list%3B%0A%09%09%09%7D%20else%20%7B%0A%09%09%09%09%2F*%20Eaten%20partially.%20*%2F%0A%0A%09%09%09%09if%20(skb_shared(list))%20%7B%0A%09%09%09%09%09%2F*%20Sucks!%20We%20need%20to%20fork%20list.%20%3A-(%20*%2F%0A%09%09%09%09%09clone%20%3D%20skb_clone(list%2C%20GFP_ATOMIC)%3B%0A%09%09%09%09%09if%20(!clone)%0A%09%09%09%09%09%09return%20NULL%3B%0A%09%09%09%09%09insp%20%3D%20list-%3Enext%3B%0A%09%09%09%09%09list%20%3D%20clone%3B%0A%09%09%09%09%7D%20else%20%7B%0A%09%09%09%09%09%2F*%20This%20may%20be%20pulled%20without%0A%09%09%09%09%09%20*%20problems.%20*%2F%0A%09%09%09%09%09insp%20%3D%20list%3B%0A%09%09%09%09%7D%0A%09%09%09%09if%20(!pskb_pull(list%2C%20eat))%20%7B%0A%09%09%09%09%09kfree_skb(clone)%3B%0A%09%09%09%09%09return%20NULL%3B%0A%09%09%09%09%7D%0A%09%09%09%09break%3B%0A%09%09%09%7D%0A%09%09%7D%20while%20(eat)%3B%0A%0A%09%09%2F*%20Free%20pulled%20out%20fragments.%20*%2F%0A%09%09while%20((list%20%3D%20skb_shinfo(skb)-%3Efrag_list)%20!%3D%20insp)%20%7B%0A%09%09%09skb_shinfo(skb)-%3Efrag_list%20%3D%20list-%3Enext%3B%0A%09%09%09kfree_skb(list)%3B%0A%09%09%7D%0A%09%09%2F*%20And%20insert%20new%20clone%20at%20head.%20*%2F%0A%09%09if%20(clone)%20%7B%0A%09%09%09clone-%3Enext%20%3D%20list%3B%0A%09%09%09skb_shinfo(skb)-%3Efrag_list%20%3D%20clone%3B%0A%09%09%7D%0A%09%7D%0A%09%2F*%20Success!%20Now%20we%20may%20commit%20changes%20to%20skb%20data.%20*%2F%0A%0Apull_pages%3A%0A%09eat%20%3D%20delta%3B%0A%09k%20%3D%200%3B%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20size%20%3D%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%0A%09%09if%20(size%20%3C%3D%20eat)%20%7B%0A%09%09%09skb_frag_unref(skb%2C%20i)%3B%0A%09%09%09eat%20-%3D%20size%3B%0A%09%09%7D%20else%20%7B%0A%09%09%09skb_shinfo(skb)-%3Efrags%5Bk%5D%20%3D%20skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%09%09%09if%20(eat)%20%7B%0A%09%09%09%09skb_shinfo(skb)-%3Efrags%5Bk%5D.page_offset%20%2B%3D%20eat%3B%0A%09%09%09%09skb_frag_size_sub(%26skb_shinfo(skb)-%3Efrags%5Bk%5D%2C%20eat)%3B%0A%09%09%09%09eat%20%3D%200%3B%0A%09%09%09%7D%0A%09%09%09k%2B%2B%3B%0A%09%09%7D%0A%09%7D%0A%09skb_shinfo(skb)-%3Enr_frags%20%3D%20k%3B%0A%0A%09skb-%3Etail%20%20%20%20%20%2B%3D%20delta%3B%0A%09skb-%3Edata_len%20-%3D%20delta%3B%0A%0A%09return%20skb_tail_pointer(skb)%3B%0A%7D%0AEXPORT_SYMBOL(__pskb_pull_tail)%3B%0A%0A%2F**%0A%20*%09skb_copy_bits%20-%20copy%20bits%20from%20skb%20to%20kernel%20buffer%0A%20*%09%40skb%3A%20source%20skb%0A%20*%09%40offset%3A%20offset%20in%20source%0A%20*%09%40to%3A%20destination%20buffer%0A%20*%09%40len%3A%20number%20of%20bytes%20to%20copy%0A%20*%0A%20*%09Copy%20the%20specified%20number%20of%20bytes%20from%20the%20source%20skb%20to%20the%0A%20*%09destination%20buffer.%0A%20*%0A%20*%09CAUTION%20!%20%3A%0A%20*%09%09If%20its%20prototype%20is%20ever%20changed%2C%0A%20*%09%09check%20arch%2F%7B*%7D%2Fnet%2F%7B*%7D.S%20files%2C%0A%20*%09%09since%20it%20is%20called%20from%20BPF%20assembly%20code.%0A%20*%2F%0Aint%20skb_copy_bits(const%20struct%20sk_buff%20*skb%2C%20int%20offset%2C%20void%20*to%2C%20int%20len)%0A%7B%0A%09int%20start%20%3D%20skb_headlen(skb)%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09int%20i%2C%20copy%3B%0A%0A%09if%20(offset%20%3E%20(int)skb-%3Elen%20-%20len)%0A%09%09goto%20fault%3B%0A%0A%09%2F*%20Copy%20header.%20*%2F%0A%09if%20((copy%20%3D%20start%20-%20offset)%20%3E%200)%20%7B%0A%09%09if%20(copy%20%3E%20len)%0A%09%09%09copy%20%3D%20len%3B%0A%09%09skb_copy_from_linear_data_offset(skb%2C%20offset%2C%20to%2C%20copy)%3B%0A%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09return%200%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%7D%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20end%3B%0A%09%09skb_frag_t%20*f%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20skb_frag_size(f)%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09u8%20*vaddr%3B%0A%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%0A%09%09%09vaddr%20%3D%20kmap_atomic(skb_frag_page(f))%3B%0A%09%09%09memcpy(to%2C%0A%09%09%09%20%20%20%20%20%20%20vaddr%20%2B%20f-%3Epage_offset%20%2B%20offset%20-%20start%2C%0A%09%09%09%20%20%20%20%20%20%20copy)%3B%0A%09%09%09kunmap_atomic(vaddr)%3B%0A%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%200%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20frag_iter-%3Elen%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09if%20(skb_copy_bits(frag_iter%2C%20offset%20-%20start%2C%20to%2C%20copy))%0A%09%09%09%09goto%20fault%3B%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%200%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09if%20(!len)%0A%09%09return%200%3B%0A%0Afault%3A%0A%09return%20-EFAULT%3B%0A%7D%0AEXPORT_SYMBOL(skb_copy_bits)%3B%0A%0A%2F*%0A%20*%20Callback%20from%20splice_to_pipe()%2C%20if%20we%20need%20to%20release%20some%20pages%0A%20*%20at%20the%20end%20of%20the%20spd%20in%20case%20we%20error'ed%20out%20in%20filling%20the%20pipe.%0A%20*%2F%0Astatic%20void%20sock_spd_release(struct%20splice_pipe_desc%20*spd%2C%20unsigned%20int%20i)%0A%7B%0A%09put_page(spd-%3Epages%5Bi%5D)%3B%0A%7D%0A%0Astatic%20struct%20page%20*linear_to_page(struct%20page%20*page%2C%20unsigned%20int%20*len%2C%0A%09%09%09%09%20%20%20unsigned%20int%20*offset%2C%0A%09%09%09%09%20%20%20struct%20sock%20*sk)%0A%7B%0A%09struct%20page_frag%20*pfrag%20%3D%20sk_page_frag(sk)%3B%0A%0A%09if%20(!sk_page_frag_refill(sk%2C%20pfrag))%0A%09%09return%20NULL%3B%0A%0A%09*len%20%3D%20min_t(unsigned%20int%2C%20*len%2C%20pfrag-%3Esize%20-%20pfrag-%3Eoffset)%3B%0A%0A%09memcpy(page_address(pfrag-%3Epage)%20%2B%20pfrag-%3Eoffset%2C%0A%09%20%20%20%20%20%20%20page_address(page)%20%2B%20*offset%2C%20*len)%3B%0A%09*offset%20%3D%20pfrag-%3Eoffset%3B%0A%09pfrag-%3Eoffset%20%2B%3D%20*len%3B%0A%0A%09return%20pfrag-%3Epage%3B%0A%7D%0A%0Astatic%20bool%20spd_can_coalesce(const%20struct%20splice_pipe_desc%20*spd%2C%0A%09%09%09%20%20%20%20%20struct%20page%20*page%2C%0A%09%09%09%20%20%20%20%20unsigned%20int%20offset)%0A%7B%0A%09return%09spd-%3Enr_pages%20%26%26%0A%09%09spd-%3Epages%5Bspd-%3Enr_pages%20-%201%5D%20%3D%3D%20page%20%26%26%0A%09%09(spd-%3Epartial%5Bspd-%3Enr_pages%20-%201%5D.offset%20%2B%0A%09%09%20spd-%3Epartial%5Bspd-%3Enr_pages%20-%201%5D.len%20%3D%3D%20offset)%3B%0A%7D%0A%0A%2F*%0A%20*%20Fill%20page%2Foffset%2Flength%20into%20spd%2C%20if%20it%20can%20hold%20more%20pages.%0A%20*%2F%0Astatic%20bool%20spd_fill_page(struct%20splice_pipe_desc%20*spd%2C%0A%09%09%09%20%20struct%20pipe_inode_info%20*pipe%2C%20struct%20page%20*page%2C%0A%09%09%09%20%20unsigned%20int%20*len%2C%20unsigned%20int%20offset%2C%0A%09%09%09%20%20bool%20linear%2C%0A%09%09%09%20%20struct%20sock%20*sk)%0A%7B%0A%09if%20(unlikely(spd-%3Enr_pages%20%3D%3D%20MAX_SKB_FRAGS))%0A%09%09return%20true%3B%0A%0A%09if%20(linear)%20%7B%0A%09%09page%20%3D%20linear_to_page(page%2C%20len%2C%20%26offset%2C%20sk)%3B%0A%09%09if%20(!page)%0A%09%09%09return%20true%3B%0A%09%7D%0A%09if%20(spd_can_coalesce(spd%2C%20page%2C%20offset))%20%7B%0A%09%09spd-%3Epartial%5Bspd-%3Enr_pages%20-%201%5D.len%20%2B%3D%20*len%3B%0A%09%09return%20false%3B%0A%09%7D%0A%09get_page(page)%3B%0A%09spd-%3Epages%5Bspd-%3Enr_pages%5D%20%3D%20page%3B%0A%09spd-%3Epartial%5Bspd-%3Enr_pages%5D.len%20%3D%20*len%3B%0A%09spd-%3Epartial%5Bspd-%3Enr_pages%5D.offset%20%3D%20offset%3B%0A%09spd-%3Enr_pages%2B%2B%3B%0A%0A%09return%20false%3B%0A%7D%0A%0Astatic%20bool%20__splice_segment(struct%20page%20*page%2C%20unsigned%20int%20poff%2C%0A%09%09%09%20%20%20%20%20unsigned%20int%20plen%2C%20unsigned%20int%20*off%2C%0A%09%09%09%20%20%20%20%20unsigned%20int%20*len%2C%0A%09%09%09%20%20%20%20%20struct%20splice_pipe_desc%20*spd%2C%20bool%20linear%2C%0A%09%09%09%20%20%20%20%20struct%20sock%20*sk%2C%0A%09%09%09%20%20%20%20%20struct%20pipe_inode_info%20*pipe)%0A%7B%0A%09if%20(!*len)%0A%09%09return%20true%3B%0A%0A%09%2F*%20skip%20this%20segment%20if%20already%20processed%20*%2F%0A%09if%20(*off%20%3E%3D%20plen)%20%7B%0A%09%09*off%20-%3D%20plen%3B%0A%09%09return%20false%3B%0A%09%7D%0A%0A%09%2F*%20ignore%20any%20bits%20we%20already%20processed%20*%2F%0A%09poff%20%2B%3D%20*off%3B%0A%09plen%20-%3D%20*off%3B%0A%09*off%20%3D%200%3B%0A%0A%09do%20%7B%0A%09%09unsigned%20int%20flen%20%3D%20min(*len%2C%20plen)%3B%0A%0A%09%09if%20(spd_fill_page(spd%2C%20pipe%2C%20page%2C%20%26flen%2C%20poff%2C%0A%09%09%09%09%20%20linear%2C%20sk))%0A%09%09%09return%20true%3B%0A%09%09poff%20%2B%3D%20flen%3B%0A%09%09plen%20-%3D%20flen%3B%0A%09%09*len%20-%3D%20flen%3B%0A%09%7D%20while%20(*len%20%26%26%20plen)%3B%0A%0A%09return%20false%3B%0A%7D%0A%0A%2F*%0A%20*%20Map%20linear%20and%20fragment%20data%20from%20the%20skb%20to%20spd.%20It%20reports%20true%20if%20the%0A%20*%20pipe%20is%20full%20or%20if%20we%20already%20spliced%20the%20requested%20length.%0A%20*%2F%0Astatic%20bool%20__skb_splice_bits(struct%20sk_buff%20*skb%2C%20struct%20pipe_inode_info%20*pipe%2C%0A%09%09%09%20%20%20%20%20%20unsigned%20int%20*offset%2C%20unsigned%20int%20*len%2C%0A%09%09%09%20%20%20%20%20%20struct%20splice_pipe_desc%20*spd%2C%20struct%20sock%20*sk)%0A%7B%0A%09int%20seg%3B%0A%0A%09%2F*%20map%20the%20linear%20part%20%3A%0A%09%20*%20If%20skb-%3Ehead_frag%20is%20set%2C%20this%20'linear'%20part%20is%20backed%20by%20a%0A%09%20*%20fragment%2C%20and%20if%20the%20head%20is%20not%20shared%20with%20any%20clones%20then%0A%09%20*%20we%20can%20avoid%20a%20copy%20since%20we%20own%20the%20head%20portion%20of%20this%20page.%0A%09%20*%2F%0A%09if%20(__splice_segment(virt_to_page(skb-%3Edata)%2C%0A%09%09%09%20%20%20%20%20(unsigned%20long)%20skb-%3Edata%20%26%20(PAGE_SIZE%20-%201)%2C%0A%09%09%09%20%20%20%20%20skb_headlen(skb)%2C%0A%09%09%09%20%20%20%20%20offset%2C%20len%2C%20spd%2C%0A%09%09%09%20%20%20%20%20skb_head_is_locked(skb)%2C%0A%09%09%09%20%20%20%20%20sk%2C%20pipe))%0A%09%09return%20true%3B%0A%0A%09%2F*%0A%09%20*%20then%20map%20the%20fragments%0A%09%20*%2F%0A%09for%20(seg%20%3D%200%3B%20seg%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20seg%2B%2B)%20%7B%0A%09%09const%20skb_frag_t%20*f%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bseg%5D%3B%0A%0A%09%09if%20(__splice_segment(skb_frag_page(f)%2C%0A%09%09%09%09%20%20%20%20%20f-%3Epage_offset%2C%20skb_frag_size(f)%2C%0A%09%09%09%09%20%20%20%20%20offset%2C%20len%2C%20spd%2C%20false%2C%20sk%2C%20pipe))%0A%09%09%09return%20true%3B%0A%09%7D%0A%0A%09return%20false%3B%0A%7D%0A%0A%2F*%0A%20*%20Map%20data%20from%20the%20skb%20to%20a%20pipe.%20Should%20handle%20both%20the%20linear%20part%2C%0A%20*%20the%20fragments%2C%20and%20the%20frag%20list.%20It%20does%20NOT%20handle%20frag%20lists%20within%0A%20*%20the%20frag%20list%2C%20if%20such%20a%20thing%20exists.%20We'd%20probably%20need%20to%20recurse%20to%0A%20*%20handle%20that%20cleanly.%0A%20*%2F%0Aint%20skb_splice_bits(struct%20sk_buff%20*skb%2C%20unsigned%20int%20offset%2C%0A%09%09%20%20%20%20struct%20pipe_inode_info%20*pipe%2C%20unsigned%20int%20tlen%2C%0A%09%09%20%20%20%20unsigned%20int%20flags)%0A%7B%0A%09struct%20partial_page%20partial%5BMAX_SKB_FRAGS%5D%3B%0A%09struct%20page%20*pages%5BMAX_SKB_FRAGS%5D%3B%0A%09struct%20splice_pipe_desc%20spd%20%3D%20%7B%0A%09%09.pages%20%3D%20pages%2C%0A%09%09.partial%20%3D%20partial%2C%0A%09%09.nr_pages_max%20%3D%20MAX_SKB_FRAGS%2C%0A%09%09.flags%20%3D%20flags%2C%0A%09%09.ops%20%3D%20%26sock_pipe_buf_ops%2C%0A%09%09.spd_release%20%3D%20sock_spd_release%2C%0A%09%7D%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09struct%20sock%20*sk%20%3D%20skb-%3Esk%3B%0A%09int%20ret%20%3D%200%3B%0A%0A%09%2F*%0A%09%20*%20__skb_splice_bits()%20only%20fails%20if%20the%20output%20has%20no%20room%20left%2C%0A%09%20*%20so%20no%20point%20in%20going%20over%20the%20frag_list%20for%20the%20error%20case.%0A%09%20*%2F%0A%09if%20(__skb_splice_bits(skb%2C%20pipe%2C%20%26offset%2C%20%26tlen%2C%20%26spd%2C%20sk))%0A%09%09goto%20done%3B%0A%09else%20if%20(!tlen)%0A%09%09goto%20done%3B%0A%0A%09%2F*%0A%09%20*%20now%20see%20if%20we%20have%20a%20frag_list%20to%20map%0A%09%20*%2F%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09if%20(!tlen)%0A%09%09%09break%3B%0A%09%09if%20(__skb_splice_bits(frag_iter%2C%20pipe%2C%20%26offset%2C%20%26tlen%2C%20%26spd%2C%20sk))%0A%09%09%09break%3B%0A%09%7D%0A%0Adone%3A%0A%09if%20(spd.nr_pages)%20%7B%0A%09%09%2F*%0A%09%09%20*%20Drop%20the%20socket%20lock%2C%20otherwise%20we%20have%20reverse%0A%09%09%20*%20locking%20dependencies%20between%20sk_lock%20and%20i_mutex%0A%09%09%20*%20here%20as%20compared%20to%20sendfile().%20We%20enter%20here%0A%09%09%20*%20with%20the%20socket%20lock%20held%2C%20and%20splice_to_pipe()%20will%0A%09%09%20*%20grab%20the%20pipe%20inode%20lock.%20For%20sendfile()%20emulation%2C%0A%09%09%20*%20we%20call%20into%20-%3Esendpage()%20with%20the%20i_mutex%20lock%20held%0A%09%09%20*%20and%20networking%20will%20grab%20the%20socket%20lock.%0A%09%09%20*%2F%0A%09%09release_sock(sk)%3B%0A%09%09ret%20%3D%20splice_to_pipe(pipe%2C%20%26spd)%3B%0A%09%09lock_sock(sk)%3B%0A%09%7D%0A%0A%09return%20ret%3B%0A%7D%0A%0A%2F**%0A%20*%09skb_store_bits%20-%20store%20bits%20from%20kernel%20buffer%20to%20skb%0A%20*%09%40skb%3A%20destination%20buffer%0A%20*%09%40offset%3A%20offset%20in%20destination%0A%20*%09%40from%3A%20source%20buffer%0A%20*%09%40len%3A%20number%20of%20bytes%20to%20copy%0A%20*%0A%20*%09Copy%20the%20specified%20number%20of%20bytes%20from%20the%20source%20buffer%20to%20the%0A%20*%09destination%20skb.%20%20This%20function%20handles%20all%20the%20messy%20bits%20of%0A%20*%09traversing%20fragment%20lists%20and%20such.%0A%20*%2F%0A%0Aint%20skb_store_bits(struct%20sk_buff%20*skb%2C%20int%20offset%2C%20const%20void%20*from%2C%20int%20len)%0A%7B%0A%09int%20start%20%3D%20skb_headlen(skb)%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09int%20i%2C%20copy%3B%0A%0A%09if%20(offset%20%3E%20(int)skb-%3Elen%20-%20len)%0A%09%09goto%20fault%3B%0A%0A%09if%20((copy%20%3D%20start%20-%20offset)%20%3E%200)%20%7B%0A%09%09if%20(copy%20%3E%20len)%0A%09%09%09copy%20%3D%20len%3B%0A%09%09skb_copy_to_linear_data_offset(skb%2C%20offset%2C%20from%2C%20copy)%3B%0A%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09return%200%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%09from%20%2B%3D%20copy%3B%0A%09%7D%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09skb_frag_t%20*frag%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20skb_frag_size(frag)%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09u8%20*vaddr%3B%0A%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%0A%09%09%09vaddr%20%3D%20kmap_atomic(skb_frag_page(frag))%3B%0A%09%09%09memcpy(vaddr%20%2B%20frag-%3Epage_offset%20%2B%20offset%20-%20start%2C%0A%09%09%09%20%20%20%20%20%20%20from%2C%20copy)%3B%0A%09%09%09kunmap_atomic(vaddr)%3B%0A%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%200%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09from%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20frag_iter-%3Elen%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09if%20(skb_store_bits(frag_iter%2C%20offset%20-%20start%2C%0A%09%09%09%09%09%20%20%20from%2C%20copy))%0A%09%09%09%09goto%20fault%3B%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%200%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09from%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%09if%20(!len)%0A%09%09return%200%3B%0A%0Afault%3A%0A%09return%20-EFAULT%3B%0A%7D%0AEXPORT_SYMBOL(skb_store_bits)%3B%0A%0A%2F*%20Checksum%20skb%20data.%20*%2F%0A%0A__wsum%20skb_checksum(const%20struct%20sk_buff%20*skb%2C%20int%20offset%2C%0A%09%09%09%20%20int%20len%2C%20__wsum%20csum)%0A%7B%0A%09int%20start%20%3D%20skb_headlen(skb)%3B%0A%09int%20i%2C%20copy%20%3D%20start%20-%20offset%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09int%20pos%20%3D%200%3B%0A%0A%09%2F*%20Checksum%20header.%20*%2F%0A%09if%20(copy%20%3E%200)%20%7B%0A%09%09if%20(copy%20%3E%20len)%0A%09%09%09copy%20%3D%20len%3B%0A%09%09csum%20%3D%20csum_partial(skb-%3Edata%20%2B%20offset%2C%20copy%2C%20csum)%3B%0A%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09return%20csum%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%09pos%09%3D%20copy%3B%0A%09%7D%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20end%3B%0A%09%09skb_frag_t%20*frag%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20skb_frag_size(frag)%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09__wsum%20csum2%3B%0A%09%09%09u8%20*vaddr%3B%0A%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09vaddr%20%3D%20kmap_atomic(skb_frag_page(frag))%3B%0A%09%09%09csum2%20%3D%20csum_partial(vaddr%20%2B%20frag-%3Epage_offset%20%2B%0A%09%09%09%09%09%20%20%20%20%20offset%20-%20start%2C%20copy%2C%200)%3B%0A%09%09%09kunmap_atomic(vaddr)%3B%0A%09%09%09csum%20%3D%20csum_block_add(csum%2C%20csum2%2C%20pos)%3B%0A%09%09%09if%20(!(len%20-%3D%20copy))%0A%09%09%09%09return%20csum%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09pos%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20frag_iter-%3Elen%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09__wsum%20csum2%3B%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09csum2%20%3D%20skb_checksum(frag_iter%2C%20offset%20-%20start%2C%0A%09%09%09%09%09%20%20%20%20%20copy%2C%200)%3B%0A%09%09%09csum%20%3D%20csum_block_add(csum%2C%20csum2%2C%20pos)%3B%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%20csum%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09pos%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%09BUG_ON(len)%3B%0A%0A%09return%20csum%3B%0A%7D%0AEXPORT_SYMBOL(skb_checksum)%3B%0A%0A%2F*%20Both%20of%20above%20in%20one%20bottle.%20*%2F%0A%0A__wsum%20skb_copy_and_csum_bits(const%20struct%20sk_buff%20*skb%2C%20int%20offset%2C%0A%09%09%09%09%20%20%20%20u8%20*to%2C%20int%20len%2C%20__wsum%20csum)%0A%7B%0A%09int%20start%20%3D%20skb_headlen(skb)%3B%0A%09int%20i%2C%20copy%20%3D%20start%20-%20offset%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09int%20pos%20%3D%200%3B%0A%0A%09%2F*%20Copy%20header.%20*%2F%0A%09if%20(copy%20%3E%200)%20%7B%0A%09%09if%20(copy%20%3E%20len)%0A%09%09%09copy%20%3D%20len%3B%0A%09%09csum%20%3D%20csum_partial_copy_nocheck(skb-%3Edata%20%2B%20offset%2C%20to%2C%0A%09%09%09%09%09%09%20copy%2C%20csum)%3B%0A%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09return%20csum%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%09pos%09%3D%20copy%3B%0A%09%7D%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09__wsum%20csum2%3B%0A%09%09%09u8%20*vaddr%3B%0A%09%09%09skb_frag_t%20*frag%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09vaddr%20%3D%20kmap_atomic(skb_frag_page(frag))%3B%0A%09%09%09csum2%20%3D%20csum_partial_copy_nocheck(vaddr%20%2B%0A%09%09%09%09%09%09%09%20%20frag-%3Epage_offset%20%2B%0A%09%09%09%09%09%09%09%20%20offset%20-%20start%2C%20to%2C%0A%09%09%09%09%09%09%09%20%20copy%2C%200)%3B%0A%09%09%09kunmap_atomic(vaddr)%3B%0A%09%09%09csum%20%3D%20csum_block_add(csum%2C%20csum2%2C%20pos)%3B%0A%09%09%09if%20(!(len%20-%3D%20copy))%0A%09%09%09%09return%20csum%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%09%09pos%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09__wsum%20csum2%3B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20frag_iter-%3Elen%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09csum2%20%3D%20skb_copy_and_csum_bits(frag_iter%2C%0A%09%09%09%09%09%09%20%20%20%20%20%20%20offset%20-%20start%2C%0A%09%09%09%09%09%09%20%20%20%20%20%20%20to%2C%20copy%2C%200)%3B%0A%09%09%09csum%20%3D%20csum_block_add(csum%2C%20csum2%2C%20pos)%3B%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%20csum%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%09to%20%20%20%20%20%2B%3D%20copy%3B%0A%09%09%09pos%20%20%20%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%09BUG_ON(len)%3B%0A%09return%20csum%3B%0A%7D%0AEXPORT_SYMBOL(skb_copy_and_csum_bits)%3B%0A%0Avoid%20skb_copy_and_csum_dev(const%20struct%20sk_buff%20*skb%2C%20u8%20*to)%0A%7B%0A%09__wsum%20csum%3B%0A%09long%20csstart%3B%0A%0A%09if%20(skb-%3Eip_summed%20%3D%3D%20CHECKSUM_PARTIAL)%0A%09%09csstart%20%3D%20skb_checksum_start_offset(skb)%3B%0A%09else%0A%09%09csstart%20%3D%20skb_headlen(skb)%3B%0A%0A%09BUG_ON(csstart%20%3E%20skb_headlen(skb))%3B%0A%0A%09skb_copy_from_linear_data(skb%2C%20to%2C%20csstart)%3B%0A%0A%09csum%20%3D%200%3B%0A%09if%20(csstart%20!%3D%20skb-%3Elen)%0A%09%09csum%20%3D%20skb_copy_and_csum_bits(skb%2C%20csstart%2C%20to%20%2B%20csstart%2C%0A%09%09%09%09%09%20%20%20%20%20%20skb-%3Elen%20-%20csstart%2C%200)%3B%0A%0A%09if%20(skb-%3Eip_summed%20%3D%3D%20CHECKSUM_PARTIAL)%20%7B%0A%09%09long%20csstuff%20%3D%20csstart%20%2B%20skb-%3Ecsum_offset%3B%0A%0A%09%09*((__sum16%20*)(to%20%2B%20csstuff))%20%3D%20csum_fold(csum)%3B%0A%09%7D%0A%7D%0AEXPORT_SYMBOL(skb_copy_and_csum_dev)%3B%0A%0A%2F**%0A%20*%09skb_dequeue%20-%20remove%20from%20the%20head%20of%20the%20queue%0A%20*%09%40list%3A%20list%20to%20dequeue%20from%0A%20*%0A%20*%09Remove%20the%20head%20of%20the%20list.%20The%20list%20lock%20is%20taken%20so%20the%20function%0A%20*%09may%20be%20used%20safely%20with%20other%20locking%20list%20functions.%20The%20head%20item%20is%0A%20*%09returned%20or%20%25NULL%20if%20the%20list%20is%20empty.%0A%20*%2F%0A%0Astruct%20sk_buff%20*skb_dequeue(struct%20sk_buff_head%20*list)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%09struct%20sk_buff%20*result%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09result%20%3D%20__skb_dequeue(list)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%09return%20result%3B%0A%7D%0AEXPORT_SYMBOL(skb_dequeue)%3B%0A%0A%2F**%0A%20*%09skb_dequeue_tail%20-%20remove%20from%20the%20tail%20of%20the%20queue%0A%20*%09%40list%3A%20list%20to%20dequeue%20from%0A%20*%0A%20*%09Remove%20the%20tail%20of%20the%20list.%20The%20list%20lock%20is%20taken%20so%20the%20function%0A%20*%09may%20be%20used%20safely%20with%20other%20locking%20list%20functions.%20The%20tail%20item%20is%0A%20*%09returned%20or%20%25NULL%20if%20the%20list%20is%20empty.%0A%20*%2F%0Astruct%20sk_buff%20*skb_dequeue_tail(struct%20sk_buff_head%20*list)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%09struct%20sk_buff%20*result%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09result%20%3D%20__skb_dequeue_tail(list)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%09return%20result%3B%0A%7D%0AEXPORT_SYMBOL(skb_dequeue_tail)%3B%0A%0A%2F**%0A%20*%09skb_queue_purge%20-%20empty%20a%20list%0A%20*%09%40list%3A%20list%20to%20empty%0A%20*%0A%20*%09Delete%20all%20buffers%20on%20an%20%26sk_buff%20list.%20Each%20buffer%20is%20removed%20from%0A%20*%09the%20list%20and%20one%20reference%20dropped.%20This%20function%20takes%20the%20list%0A%20*%09lock%20and%20is%20atomic%20with%20respect%20to%20other%20list%20locking%20functions.%0A%20*%2F%0Avoid%20skb_queue_purge(struct%20sk_buff_head%20*list)%0A%7B%0A%09struct%20sk_buff%20*skb%3B%0A%09while%20((skb%20%3D%20skb_dequeue(list))%20!%3D%20NULL)%0A%09%09kfree_skb(skb)%3B%0A%7D%0AEXPORT_SYMBOL(skb_queue_purge)%3B%0A%0A%2F**%0A%20*%09skb_queue_head%20-%20queue%20a%20buffer%20at%20the%20list%20head%0A%20*%09%40list%3A%20list%20to%20use%0A%20*%09%40newsk%3A%20buffer%20to%20queue%0A%20*%0A%20*%09Queue%20a%20buffer%20at%20the%20start%20of%20the%20list.%20This%20function%20takes%20the%0A%20*%09list%20lock%20and%20can%20be%20used%20safely%20with%20other%20locking%20%26sk_buff%20functions%0A%20*%09safely.%0A%20*%0A%20*%09A%20buffer%20cannot%20be%20placed%20on%20two%20lists%20at%20the%20same%20time.%0A%20*%2F%0Avoid%20skb_queue_head(struct%20sk_buff_head%20*list%2C%20struct%20sk_buff%20*newsk)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09__skb_queue_head(list%2C%20newsk)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%7D%0AEXPORT_SYMBOL(skb_queue_head)%3B%0A%0A%2F**%0A%20*%09skb_queue_tail%20-%20queue%20a%20buffer%20at%20the%20list%20tail%0A%20*%09%40list%3A%20list%20to%20use%0A%20*%09%40newsk%3A%20buffer%20to%20queue%0A%20*%0A%20*%09Queue%20a%20buffer%20at%20the%20tail%20of%20the%20list.%20This%20function%20takes%20the%0A%20*%09list%20lock%20and%20can%20be%20used%20safely%20with%20other%20locking%20%26sk_buff%20functions%0A%20*%09safely.%0A%20*%0A%20*%09A%20buffer%20cannot%20be%20placed%20on%20two%20lists%20at%20the%20same%20time.%0A%20*%2F%0Avoid%20skb_queue_tail(struct%20sk_buff_head%20*list%2C%20struct%20sk_buff%20*newsk)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09__skb_queue_tail(list%2C%20newsk)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%7D%0AEXPORT_SYMBOL(skb_queue_tail)%3B%0A%0A%2F**%0A%20*%09skb_unlink%09-%09remove%20a%20buffer%20from%20a%20list%0A%20*%09%40skb%3A%20buffer%20to%20remove%0A%20*%09%40list%3A%20list%20to%20use%0A%20*%0A%20*%09Remove%20a%20packet%20from%20a%20list.%20The%20list%20locks%20are%20taken%20and%20this%0A%20*%09function%20is%20atomic%20with%20respect%20to%20other%20list%20locked%20calls%0A%20*%0A%20*%09You%20must%20know%20what%20list%20the%20SKB%20is%20on.%0A%20*%2F%0Avoid%20skb_unlink(struct%20sk_buff%20*skb%2C%20struct%20sk_buff_head%20*list)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09__skb_unlink(skb%2C%20list)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%7D%0AEXPORT_SYMBOL(skb_unlink)%3B%0A%0A%2F**%0A%20*%09skb_append%09-%09append%20a%20buffer%0A%20*%09%40old%3A%20buffer%20to%20insert%20after%0A%20*%09%40newsk%3A%20buffer%20to%20insert%0A%20*%09%40list%3A%20list%20to%20use%0A%20*%0A%20*%09Place%20a%20packet%20after%20a%20given%20packet%20in%20a%20list.%20The%20list%20locks%20are%20taken%0A%20*%09and%20this%20function%20is%20atomic%20with%20respect%20to%20other%20list%20locked%20calls.%0A%20*%09A%20buffer%20cannot%20be%20placed%20on%20two%20lists%20at%20the%20same%20time.%0A%20*%2F%0Avoid%20skb_append(struct%20sk_buff%20*old%2C%20struct%20sk_buff%20*newsk%2C%20struct%20sk_buff_head%20*list)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09__skb_queue_after(list%2C%20old%2C%20newsk)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%7D%0AEXPORT_SYMBOL(skb_append)%3B%0A%0A%2F**%0A%20*%09skb_insert%09-%09insert%20a%20buffer%0A%20*%09%40old%3A%20buffer%20to%20insert%20before%0A%20*%09%40newsk%3A%20buffer%20to%20insert%0A%20*%09%40list%3A%20list%20to%20use%0A%20*%0A%20*%09Place%20a%20packet%20before%20a%20given%20packet%20in%20a%20list.%20The%20list%20locks%20are%0A%20*%20%09taken%20and%20this%20function%20is%20atomic%20with%20respect%20to%20other%20list%20locked%0A%20*%09calls.%0A%20*%0A%20*%09A%20buffer%20cannot%20be%20placed%20on%20two%20lists%20at%20the%20same%20time.%0A%20*%2F%0Avoid%20skb_insert(struct%20sk_buff%20*old%2C%20struct%20sk_buff%20*newsk%2C%20struct%20sk_buff_head%20*list)%0A%7B%0A%09unsigned%20long%20flags%3B%0A%0A%09spin_lock_irqsave(%26list-%3Elock%2C%20flags)%3B%0A%09__skb_insert(newsk%2C%20old-%3Eprev%2C%20old%2C%20list)%3B%0A%09spin_unlock_irqrestore(%26list-%3Elock%2C%20flags)%3B%0A%7D%0AEXPORT_SYMBOL(skb_insert)%3B%0A%0Astatic%20inline%20void%20skb_split_inside_header(struct%20sk_buff%20*skb%2C%0A%09%09%09%09%09%20%20%20struct%20sk_buff*%20skb1%2C%0A%09%09%09%09%09%20%20%20const%20u32%20len%2C%20const%20int%20pos)%0A%7B%0A%09int%20i%3B%0A%0A%09skb_copy_from_linear_data_offset(skb%2C%20len%2C%20skb_put(skb1%2C%20pos%20-%20len)%2C%0A%09%09%09%09%09%20pos%20-%20len)%3B%0A%09%2F*%20And%20move%20data%20appendix%20as%20is.%20*%2F%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%0A%09%09skb_shinfo(skb1)-%3Efrags%5Bi%5D%20%3D%20skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09skb_shinfo(skb1)-%3Enr_frags%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%09skb_shinfo(skb)-%3Enr_frags%20%20%3D%200%3B%0A%09skb1-%3Edata_len%09%09%20%20%20%3D%20skb-%3Edata_len%3B%0A%09skb1-%3Elen%09%09%20%20%20%2B%3D%20skb1-%3Edata_len%3B%0A%09skb-%3Edata_len%09%09%20%20%20%3D%200%3B%0A%09skb-%3Elen%09%09%20%20%20%3D%20len%3B%0A%09skb_set_tail_pointer(skb%2C%20len)%3B%0A%7D%0A%0Astatic%20inline%20void%20skb_split_no_header(struct%20sk_buff%20*skb%2C%0A%09%09%09%09%20%20%20%20%20%20%20struct%20sk_buff*%20skb1%2C%0A%09%09%09%09%20%20%20%20%20%20%20const%20u32%20len%2C%20int%20pos)%0A%7B%0A%09int%20i%2C%20k%20%3D%200%3B%0A%09const%20int%20nfrags%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%0A%09skb_shinfo(skb)-%3Enr_frags%20%3D%200%3B%0A%09skb1-%3Elen%09%09%20%20%3D%20skb1-%3Edata_len%20%3D%20skb-%3Elen%20-%20len%3B%0A%09skb-%3Elen%09%09%20%20%3D%20len%3B%0A%09skb-%3Edata_len%09%09%20%20%3D%20len%20-%20pos%3B%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20nfrags%3B%20i%2B%2B)%20%7B%0A%09%09int%20size%20%3D%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%0A%09%09if%20(pos%20%2B%20size%20%3E%20len)%20%7B%0A%09%09%09skb_shinfo(skb1)-%3Efrags%5Bk%5D%20%3D%20skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09%09if%20(pos%20%3C%20len)%20%7B%0A%09%09%09%09%2F*%20Split%20frag.%0A%09%09%09%09%20*%20We%20have%20two%20variants%20in%20this%20case%3A%0A%09%09%09%09%20*%201.%20Move%20all%20the%20frag%20to%20the%20second%0A%09%09%09%09%20*%20%20%20%20part%2C%20if%20it%20is%20possible.%20F.e.%0A%09%09%09%09%20*%20%20%20%20this%20approach%20is%20mandatory%20for%20TUX%2C%0A%09%09%09%09%20*%20%20%20%20where%20splitting%20is%20expensive.%0A%09%09%09%09%20*%202.%20Split%20is%20accurately.%20We%20make%20this.%0A%09%09%09%09%20*%2F%0A%09%09%09%09skb_frag_ref(skb%2C%20i)%3B%0A%09%09%09%09skb_shinfo(skb1)-%3Efrags%5B0%5D.page_offset%20%2B%3D%20len%20-%20pos%3B%0A%09%09%09%09skb_frag_size_sub(%26skb_shinfo(skb1)-%3Efrags%5B0%5D%2C%20len%20-%20pos)%3B%0A%09%09%09%09skb_frag_size_set(%26skb_shinfo(skb)-%3Efrags%5Bi%5D%2C%20len%20-%20pos)%3B%0A%09%09%09%09skb_shinfo(skb)-%3Enr_frags%2B%2B%3B%0A%09%09%09%7D%0A%09%09%09k%2B%2B%3B%0A%09%09%7D%20else%0A%09%09%09skb_shinfo(skb)-%3Enr_frags%2B%2B%3B%0A%09%09pos%20%2B%3D%20size%3B%0A%09%7D%0A%09skb_shinfo(skb1)-%3Enr_frags%20%3D%20k%3B%0A%7D%0A%0A%2F**%0A%20*%20skb_split%20-%20Split%20fragmented%20skb%20to%20two%20parts%20at%20length%20len.%0A%20*%20%40skb%3A%20the%20buffer%20to%20split%0A%20*%20%40skb1%3A%20the%20buffer%20to%20receive%20the%20second%20part%0A%20*%20%40len%3A%20new%20length%20for%20skb%0A%20*%2F%0Avoid%20skb_split(struct%20sk_buff%20*skb%2C%20struct%20sk_buff%20*skb1%2C%20const%20u32%20len)%0A%7B%0A%09int%20pos%20%3D%20skb_headlen(skb)%3B%0A%0A%09skb_shinfo(skb1)-%3Etx_flags%20%3D%20skb_shinfo(skb)-%3Etx_flags%20%26%20SKBTX_SHARED_FRAG%3B%0A%09if%20(len%20%3C%20pos)%09%2F*%20Split%20line%20is%20inside%20header.%20*%2F%0A%09%09skb_split_inside_header(skb%2C%20skb1%2C%20len%2C%20pos)%3B%0A%09else%09%09%2F*%20Second%20chunk%20has%20no%20header%2C%20nothing%20to%20copy.%20*%2F%0A%09%09skb_split_no_header(skb%2C%20skb1%2C%20len%2C%20pos)%3B%0A%7D%0AEXPORT_SYMBOL(skb_split)%3B%0A%0A%2F*%20Shifting%20from%2Fto%20a%20cloned%20skb%20is%20a%20no-go.%0A%20*%0A%20*%20Caller%20cannot%20keep%20skb_shinfo%20related%20pointers%20past%20calling%20here!%0A%20*%2F%0Astatic%20int%20skb_prepare_for_shift(struct%20sk_buff%20*skb)%0A%7B%0A%09return%20skb_cloned(skb)%20%26%26%20pskb_expand_head(skb%2C%200%2C%200%2C%20GFP_ATOMIC)%3B%0A%7D%0A%0A%2F**%0A%20*%20skb_shift%20-%20Shifts%20paged%20data%20partially%20from%20skb%20to%20another%0A%20*%20%40tgt%3A%20buffer%20into%20which%20tail%20data%20gets%20added%0A%20*%20%40skb%3A%20buffer%20from%20which%20the%20paged%20data%20comes%20from%0A%20*%20%40shiftlen%3A%20shift%20up%20to%20this%20many%20bytes%0A%20*%0A%20*%20Attempts%20to%20shift%20up%20to%20shiftlen%20worth%20of%20bytes%2C%20which%20may%20be%20less%20than%0A%20*%20the%20length%20of%20the%20skb%2C%20from%20skb%20to%20tgt.%20Returns%20number%20bytes%20shifted.%0A%20*%20It's%20up%20to%20caller%20to%20free%20skb%20if%20everything%20was%20shifted.%0A%20*%0A%20*%20If%20%40tgt%20runs%20out%20of%20frags%2C%20the%20whole%20operation%20is%20aborted.%0A%20*%0A%20*%20Skb%20cannot%20include%20anything%20else%20but%20paged%20data%20while%20tgt%20is%20allowed%0A%20*%20to%20have%20non-paged%20data%20as%20well.%0A%20*%0A%20*%20TODO%3A%20full%20sized%20shift%20could%20be%20optimized%20but%20that%20would%20need%0A%20*%20specialized%20skb%20free'er%20to%20handle%20frags%20without%20up-to-date%20nr_frags.%0A%20*%2F%0Aint%20skb_shift(struct%20sk_buff%20*tgt%2C%20struct%20sk_buff%20*skb%2C%20int%20shiftlen)%0A%7B%0A%09int%20from%2C%20to%2C%20merge%2C%20todo%3B%0A%09struct%20skb_frag_struct%20*fragfrom%2C%20*fragto%3B%0A%0A%09BUG_ON(shiftlen%20%3E%20skb-%3Elen)%3B%0A%09BUG_ON(skb_headlen(skb))%3B%09%2F*%20Would%20corrupt%20stream%20*%2F%0A%0A%09todo%20%3D%20shiftlen%3B%0A%09from%20%3D%200%3B%0A%09to%20%3D%20skb_shinfo(tgt)-%3Enr_frags%3B%0A%09fragfrom%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bfrom%5D%3B%0A%0A%09%2F*%20Actual%20merge%20is%20delayed%20until%20the%20point%20when%20we%20know%20we%20can%0A%09%20*%20commit%20all%2C%20so%20that%20we%20don't%20have%20to%20undo%20partial%20changes%0A%09%20*%2F%0A%09if%20(!to%20%7C%7C%0A%09%20%20%20%20!skb_can_coalesce(tgt%2C%20to%2C%20skb_frag_page(fragfrom)%2C%0A%09%09%09%20%20%20%20%20%20fragfrom-%3Epage_offset))%20%7B%0A%09%09merge%20%3D%20-1%3B%0A%09%7D%20else%20%7B%0A%09%09merge%20%3D%20to%20-%201%3B%0A%0A%09%09todo%20-%3D%20skb_frag_size(fragfrom)%3B%0A%09%09if%20(todo%20%3C%200)%20%7B%0A%09%09%09if%20(skb_prepare_for_shift(skb)%20%7C%7C%0A%09%09%09%20%20%20%20skb_prepare_for_shift(tgt))%0A%09%09%09%09return%200%3B%0A%0A%09%09%09%2F*%20All%20previous%20frag%20pointers%20might%20be%20stale!%20*%2F%0A%09%09%09fragfrom%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bfrom%5D%3B%0A%09%09%09fragto%20%3D%20%26skb_shinfo(tgt)-%3Efrags%5Bmerge%5D%3B%0A%0A%09%09%09skb_frag_size_add(fragto%2C%20shiftlen)%3B%0A%09%09%09skb_frag_size_sub(fragfrom%2C%20shiftlen)%3B%0A%09%09%09fragfrom-%3Epage_offset%20%2B%3D%20shiftlen%3B%0A%0A%09%09%09goto%20onlymerged%3B%0A%09%09%7D%0A%0A%09%09from%2B%2B%3B%0A%09%7D%0A%0A%09%2F*%20Skip%20full%2C%20not-fitting%20skb%20to%20avoid%20expensive%20operations%20*%2F%0A%09if%20((shiftlen%20%3D%3D%20skb-%3Elen)%20%26%26%0A%09%20%20%20%20(skb_shinfo(skb)-%3Enr_frags%20-%20from)%20%3E%20(MAX_SKB_FRAGS%20-%20to))%0A%09%09return%200%3B%0A%0A%09if%20(skb_prepare_for_shift(skb)%20%7C%7C%20skb_prepare_for_shift(tgt))%0A%09%09return%200%3B%0A%0A%09while%20((todo%20%3E%200)%20%26%26%20(from%20%3C%20skb_shinfo(skb)-%3Enr_frags))%20%7B%0A%09%09if%20(to%20%3D%3D%20MAX_SKB_FRAGS)%0A%09%09%09return%200%3B%0A%0A%09%09fragfrom%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bfrom%5D%3B%0A%09%09fragto%20%3D%20%26skb_shinfo(tgt)-%3Efrags%5Bto%5D%3B%0A%0A%09%09if%20(todo%20%3E%3D%20skb_frag_size(fragfrom))%20%7B%0A%09%09%09*fragto%20%3D%20*fragfrom%3B%0A%09%09%09todo%20-%3D%20skb_frag_size(fragfrom)%3B%0A%09%09%09from%2B%2B%3B%0A%09%09%09to%2B%2B%3B%0A%0A%09%09%7D%20else%20%7B%0A%09%09%09__skb_frag_ref(fragfrom)%3B%0A%09%09%09fragto-%3Epage%20%3D%20fragfrom-%3Epage%3B%0A%09%09%09fragto-%3Epage_offset%20%3D%20fragfrom-%3Epage_offset%3B%0A%09%09%09skb_frag_size_set(fragto%2C%20todo)%3B%0A%0A%09%09%09fragfrom-%3Epage_offset%20%2B%3D%20todo%3B%0A%09%09%09skb_frag_size_sub(fragfrom%2C%20todo)%3B%0A%09%09%09todo%20%3D%200%3B%0A%0A%09%09%09to%2B%2B%3B%0A%09%09%09break%3B%0A%09%09%7D%0A%09%7D%0A%0A%09%2F*%20Ready%20to%20%22commit%22%20this%20state%20change%20to%20tgt%20*%2F%0A%09skb_shinfo(tgt)-%3Enr_frags%20%3D%20to%3B%0A%0A%09if%20(merge%20%3E%3D%200)%20%7B%0A%09%09fragfrom%20%3D%20%26skb_shinfo(skb)-%3Efrags%5B0%5D%3B%0A%09%09fragto%20%3D%20%26skb_shinfo(tgt)-%3Efrags%5Bmerge%5D%3B%0A%0A%09%09skb_frag_size_add(fragto%2C%20skb_frag_size(fragfrom))%3B%0A%09%09__skb_frag_unref(fragfrom)%3B%0A%09%7D%0A%0A%09%2F*%20Reposition%20in%20the%20original%20skb%20*%2F%0A%09to%20%3D%200%3B%0A%09while%20(from%20%3C%20skb_shinfo(skb)-%3Enr_frags)%0A%09%09skb_shinfo(skb)-%3Efrags%5Bto%2B%2B%5D%20%3D%20skb_shinfo(skb)-%3Efrags%5Bfrom%2B%2B%5D%3B%0A%09skb_shinfo(skb)-%3Enr_frags%20%3D%20to%3B%0A%0A%09BUG_ON(todo%20%3E%200%20%26%26%20!skb_shinfo(skb)-%3Enr_frags)%3B%0A%0Aonlymerged%3A%0A%09%2F*%20Most%20likely%20the%20tgt%20won't%20ever%20need%20its%20checksum%20anymore%2C%20skb%20on%0A%09%20*%20the%20other%20hand%20might%20need%20it%20if%20it%20needs%20to%20be%20resent%0A%09%20*%2F%0A%09tgt-%3Eip_summed%20%3D%20CHECKSUM_PARTIAL%3B%0A%09skb-%3Eip_summed%20%3D%20CHECKSUM_PARTIAL%3B%0A%0A%09%2F*%20Yak%2C%20is%20it%20really%20working%20this%20way%3F%20Some%20helper%20please%3F%20*%2F%0A%09skb-%3Elen%20-%3D%20shiftlen%3B%0A%09skb-%3Edata_len%20-%3D%20shiftlen%3B%0A%09skb-%3Etruesize%20-%3D%20shiftlen%3B%0A%09tgt-%3Elen%20%2B%3D%20shiftlen%3B%0A%09tgt-%3Edata_len%20%2B%3D%20shiftlen%3B%0A%09tgt-%3Etruesize%20%2B%3D%20shiftlen%3B%0A%0A%09return%20shiftlen%3B%0A%7D%0A%0A%2F**%0A%20*%20skb_prepare_seq_read%20-%20Prepare%20a%20sequential%20read%20of%20skb%20data%0A%20*%20%40skb%3A%20the%20buffer%20to%20read%0A%20*%20%40from%3A%20lower%20offset%20of%20data%20to%20be%20read%0A%20*%20%40to%3A%20upper%20offset%20of%20data%20to%20be%20read%0A%20*%20%40st%3A%20state%20variable%0A%20*%0A%20*%20Initializes%20the%20specified%20state%20variable.%20Must%20be%20called%20before%0A%20*%20invoking%20skb_seq_read()%20for%20the%20first%20time.%0A%20*%2F%0Avoid%20skb_prepare_seq_read(struct%20sk_buff%20*skb%2C%20unsigned%20int%20from%2C%0A%09%09%09%20%20unsigned%20int%20to%2C%20struct%20skb_seq_state%20*st)%0A%7B%0A%09st-%3Elower_offset%20%3D%20from%3B%0A%09st-%3Eupper_offset%20%3D%20to%3B%0A%09st-%3Eroot_skb%20%3D%20st-%3Ecur_skb%20%3D%20skb%3B%0A%09st-%3Efrag_idx%20%3D%20st-%3Estepped_offset%20%3D%200%3B%0A%09st-%3Efrag_data%20%3D%20NULL%3B%0A%7D%0AEXPORT_SYMBOL(skb_prepare_seq_read)%3B%0A%0A%2F**%0A%20*%20skb_seq_read%20-%20Sequentially%20read%20skb%20data%0A%20*%20%40consumed%3A%20number%20of%20bytes%20consumed%20by%20the%20caller%20so%20far%0A%20*%20%40data%3A%20destination%20pointer%20for%20data%20to%20be%20returned%0A%20*%20%40st%3A%20state%20variable%0A%20*%0A%20*%20Reads%20a%20block%20of%20skb%20data%20at%20%26consumed%20relative%20to%20the%0A%20*%20lower%20offset%20specified%20to%20skb_prepare_seq_read().%20Assigns%0A%20*%20the%20head%20of%20the%20data%20block%20to%20%26data%20and%20returns%20the%20length%0A%20*%20of%20the%20block%20or%200%20if%20the%20end%20of%20the%20skb%20data%20or%20the%20upper%0A%20*%20offset%20has%20been%20reached.%0A%20*%0A%20*%20The%20caller%20is%20not%20required%20to%20consume%20all%20of%20the%20data%0A%20*%20returned%2C%20i.e.%20%26consumed%20is%20typically%20set%20to%20the%20number%0A%20*%20of%20bytes%20already%20consumed%20and%20the%20next%20call%20to%0A%20*%20skb_seq_read()%20will%20return%20the%20remaining%20part%20of%20the%20block.%0A%20*%0A%20*%20Note%201%3A%20The%20size%20of%20each%20block%20of%20data%20returned%20can%20be%20arbitrary%2C%0A%20*%20%20%20%20%20%20%20this%20limitation%20is%20the%20cost%20for%20zerocopy%20seqeuental%0A%20*%20%20%20%20%20%20%20reads%20of%20potentially%20non%20linear%20data.%0A%20*%0A%20*%20Note%202%3A%20Fragment%20lists%20within%20fragments%20are%20not%20implemented%0A%20*%20%20%20%20%20%20%20at%20the%20moment%2C%20state-%3Eroot_skb%20could%20be%20replaced%20with%0A%20*%20%20%20%20%20%20%20a%20stack%20for%20this%20purpose.%0A%20*%2F%0Aunsigned%20int%20skb_seq_read(unsigned%20int%20consumed%2C%20const%20u8%20**data%2C%0A%09%09%09%20%20struct%20skb_seq_state%20*st)%0A%7B%0A%09unsigned%20int%20block_limit%2C%20abs_offset%20%3D%20consumed%20%2B%20st-%3Elower_offset%3B%0A%09skb_frag_t%20*frag%3B%0A%0A%09if%20(unlikely(abs_offset%20%3E%3D%20st-%3Eupper_offset))%0A%09%09return%200%3B%0A%0Anext_skb%3A%0A%09block_limit%20%3D%20skb_headlen(st-%3Ecur_skb)%20%2B%20st-%3Estepped_offset%3B%0A%0A%09if%20(abs_offset%20%3C%20block_limit%20%26%26%20!st-%3Efrag_data)%20%7B%0A%09%09*data%20%3D%20st-%3Ecur_skb-%3Edata%20%2B%20(abs_offset%20-%20st-%3Estepped_offset)%3B%0A%09%09return%20block_limit%20-%20abs_offset%3B%0A%09%7D%0A%0A%09if%20(st-%3Efrag_idx%20%3D%3D%200%20%26%26%20!st-%3Efrag_data)%0A%09%09st-%3Estepped_offset%20%2B%3D%20skb_headlen(st-%3Ecur_skb)%3B%0A%0A%09while%20(st-%3Efrag_idx%20%3C%20skb_shinfo(st-%3Ecur_skb)-%3Enr_frags)%20%7B%0A%09%09frag%20%3D%20%26skb_shinfo(st-%3Ecur_skb)-%3Efrags%5Bst-%3Efrag_idx%5D%3B%0A%09%09block_limit%20%3D%20skb_frag_size(frag)%20%2B%20st-%3Estepped_offset%3B%0A%0A%09%09if%20(abs_offset%20%3C%20block_limit)%20%7B%0A%09%09%09if%20(!st-%3Efrag_data)%0A%09%09%09%09st-%3Efrag_data%20%3D%20kmap_atomic(skb_frag_page(frag))%3B%0A%0A%09%09%09*data%20%3D%20(u8%20*)%20st-%3Efrag_data%20%2B%20frag-%3Epage_offset%20%2B%0A%09%09%09%09(abs_offset%20-%20st-%3Estepped_offset)%3B%0A%0A%09%09%09return%20block_limit%20-%20abs_offset%3B%0A%09%09%7D%0A%0A%09%09if%20(st-%3Efrag_data)%20%7B%0A%09%09%09kunmap_atomic(st-%3Efrag_data)%3B%0A%09%09%09st-%3Efrag_data%20%3D%20NULL%3B%0A%09%09%7D%0A%0A%09%09st-%3Efrag_idx%2B%2B%3B%0A%09%09st-%3Estepped_offset%20%2B%3D%20skb_frag_size(frag)%3B%0A%09%7D%0A%0A%09if%20(st-%3Efrag_data)%20%7B%0A%09%09kunmap_atomic(st-%3Efrag_data)%3B%0A%09%09st-%3Efrag_data%20%3D%20NULL%3B%0A%09%7D%0A%0A%09if%20(st-%3Eroot_skb%20%3D%3D%20st-%3Ecur_skb%20%26%26%20skb_has_frag_list(st-%3Eroot_skb))%20%7B%0A%09%09st-%3Ecur_skb%20%3D%20skb_shinfo(st-%3Eroot_skb)-%3Efrag_list%3B%0A%09%09st-%3Efrag_idx%20%3D%200%3B%0A%09%09goto%20next_skb%3B%0A%09%7D%20else%20if%20(st-%3Ecur_skb-%3Enext)%20%7B%0A%09%09st-%3Ecur_skb%20%3D%20st-%3Ecur_skb-%3Enext%3B%0A%09%09st-%3Efrag_idx%20%3D%200%3B%0A%09%09goto%20next_skb%3B%0A%09%7D%0A%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL(skb_seq_read)%3B%0A%0A%2F**%0A%20*%20skb_abort_seq_read%20-%20Abort%20a%20sequential%20read%20of%20skb%20data%0A%20*%20%40st%3A%20state%20variable%0A%20*%0A%20*%20Must%20be%20called%20if%20skb_seq_read()%20was%20not%20called%20until%20it%0A%20*%20returned%200.%0A%20*%2F%0Avoid%20skb_abort_seq_read(struct%20skb_seq_state%20*st)%0A%7B%0A%09if%20(st-%3Efrag_data)%0A%09%09kunmap_atomic(st-%3Efrag_data)%3B%0A%7D%0AEXPORT_SYMBOL(skb_abort_seq_read)%3B%0A%0A%23define%20TS_SKB_CB(state)%09((struct%20skb_seq_state%20*)%20%26((state)-%3Ecb))%0A%0Astatic%20unsigned%20int%20skb_ts_get_next_block(unsigned%20int%20offset%2C%20const%20u8%20**text%2C%0A%09%09%09%09%09%20%20struct%20ts_config%20*conf%2C%0A%09%09%09%09%09%20%20struct%20ts_state%20*state)%0A%7B%0A%09return%20skb_seq_read(offset%2C%20text%2C%20TS_SKB_CB(state))%3B%0A%7D%0A%0Astatic%20void%20skb_ts_finish(struct%20ts_config%20*conf%2C%20struct%20ts_state%20*state)%0A%7B%0A%09skb_abort_seq_read(TS_SKB_CB(state))%3B%0A%7D%0A%0A%2F**%0A%20*%20skb_find_text%20-%20Find%20a%20text%20pattern%20in%20skb%20data%0A%20*%20%40skb%3A%20the%20buffer%20to%20look%20in%0A%20*%20%40from%3A%20search%20offset%0A%20*%20%40to%3A%20search%20limit%0A%20*%20%40config%3A%20textsearch%20configuration%0A%20*%20%40state%3A%20uninitialized%20textsearch%20state%20variable%0A%20*%0A%20*%20Finds%20a%20pattern%20in%20the%20skb%20data%20according%20to%20the%20specified%0A%20*%20textsearch%20configuration.%20Use%20textsearch_next()%20to%20retrieve%0A%20*%20subsequent%20occurrences%20of%20the%20pattern.%20Returns%20the%20offset%0A%20*%20to%20the%20first%20occurrence%20or%20UINT_MAX%20if%20no%20match%20was%20found.%0A%20*%2F%0Aunsigned%20int%20skb_find_text(struct%20sk_buff%20*skb%2C%20unsigned%20int%20from%2C%0A%09%09%09%20%20%20unsigned%20int%20to%2C%20struct%20ts_config%20*config%2C%0A%09%09%09%20%20%20struct%20ts_state%20*state)%0A%7B%0A%09unsigned%20int%20ret%3B%0A%0A%09config-%3Eget_next_block%20%3D%20skb_ts_get_next_block%3B%0A%09config-%3Efinish%20%3D%20skb_ts_finish%3B%0A%0A%09skb_prepare_seq_read(skb%2C%20from%2C%20to%2C%20TS_SKB_CB(state))%3B%0A%0A%09ret%20%3D%20textsearch_find(config%2C%20state)%3B%0A%09return%20(ret%20%3C%3D%20to%20-%20from%20%3F%20ret%20%3A%20UINT_MAX)%3B%0A%7D%0AEXPORT_SYMBOL(skb_find_text)%3B%0A%0A%2F**%0A%20*%20skb_append_datato_frags%20-%20append%20the%20user%20data%20to%20a%20skb%0A%20*%20%40sk%3A%20sock%20%20structure%0A%20*%20%40skb%3A%20skb%20structure%20to%20be%20appened%20with%20user%20data.%0A%20*%20%40getfrag%3A%20call%20back%20function%20to%20be%20used%20for%20getting%20the%20user%20data%0A%20*%20%40from%3A%20pointer%20to%20user%20message%20iov%0A%20*%20%40length%3A%20length%20of%20the%20iov%20message%0A%20*%0A%20*%20Description%3A%20This%20procedure%20append%20the%20user%20data%20in%20the%20fragment%20part%0A%20*%20of%20the%20skb%20if%20any%20page%20alloc%20fails%20user%20this%20procedure%20returns%20%20-ENOMEM%0A%20*%2F%0Aint%20skb_append_datato_frags(struct%20sock%20*sk%2C%20struct%20sk_buff%20*skb%2C%0A%09%09%09int%20(*getfrag)(void%20*from%2C%20char%20*to%2C%20int%20offset%2C%0A%09%09%09%09%09int%20len%2C%20int%20odd%2C%20struct%20sk_buff%20*skb)%2C%0A%09%09%09void%20*from%2C%20int%20length)%0A%7B%0A%09int%20frg_cnt%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%09int%20copy%3B%0A%09int%20offset%20%3D%200%3B%0A%09int%20ret%3B%0A%09struct%20page_frag%20*pfrag%20%3D%20%26current-%3Etask_frag%3B%0A%0A%09do%20%7B%0A%09%09%2F*%20Return%20error%20if%20we%20don't%20have%20space%20for%20new%20frag%20*%2F%0A%09%09if%20(frg_cnt%20%3E%3D%20MAX_SKB_FRAGS)%0A%09%09%09return%20-EMSGSIZE%3B%0A%0A%09%09if%20(!sk_page_frag_refill(sk%2C%20pfrag))%0A%09%09%09return%20-ENOMEM%3B%0A%0A%09%09%2F*%20copy%20the%20user%20data%20to%20page%20*%2F%0A%09%09copy%20%3D%20min_t(int%2C%20length%2C%20pfrag-%3Esize%20-%20pfrag-%3Eoffset)%3B%0A%0A%09%09ret%20%3D%20getfrag(from%2C%20page_address(pfrag-%3Epage)%20%2B%20pfrag-%3Eoffset%2C%0A%09%09%09%20%20%20%20%20%20offset%2C%20copy%2C%200%2C%20skb)%3B%0A%09%09if%20(ret%20%3C%200)%0A%09%09%09return%20-EFAULT%3B%0A%0A%09%09%2F*%20copy%20was%20successful%20so%20update%20the%20size%20parameters%20*%2F%0A%09%09skb_fill_page_desc(skb%2C%20frg_cnt%2C%20pfrag-%3Epage%2C%20pfrag-%3Eoffset%2C%0A%09%09%09%09%20%20%20copy)%3B%0A%09%09frg_cnt%2B%2B%3B%0A%09%09pfrag-%3Eoffset%20%2B%3D%20copy%3B%0A%09%09get_page(pfrag-%3Epage)%3B%0A%0A%09%09skb-%3Etruesize%20%2B%3D%20copy%3B%0A%09%09atomic_add(copy%2C%20%26sk-%3Esk_wmem_alloc)%3B%0A%09%09skb-%3Elen%20%2B%3D%20copy%3B%0A%09%09skb-%3Edata_len%20%2B%3D%20copy%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%09length%20-%3D%20copy%3B%0A%0A%09%7D%20while%20(length%20%3E%200)%3B%0A%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL(skb_append_datato_frags)%3B%0A%0A%2F**%0A%20*%09skb_pull_rcsum%20-%20pull%20skb%20and%20update%20receive%20checksum%0A%20*%09%40skb%3A%20buffer%20to%20update%0A%20*%09%40len%3A%20length%20of%20data%20pulled%0A%20*%0A%20*%09This%20function%20performs%20an%20skb_pull%20on%20the%20packet%20and%20updates%0A%20*%09the%20CHECKSUM_COMPLETE%20checksum.%20%20It%20should%20be%20used%20on%0A%20*%09receive%20path%20processing%20instead%20of%20skb_pull%20unless%20you%20know%0A%20*%09that%20the%20checksum%20difference%20is%20zero%20(e.g.%2C%20a%20valid%20IP%20header)%0A%20*%09or%20you%20are%20setting%20ip_summed%20to%20CHECKSUM_NONE.%0A%20*%2F%0Aunsigned%20char%20*skb_pull_rcsum(struct%20sk_buff%20*skb%2C%20unsigned%20int%20len)%0A%7B%0A%09BUG_ON(len%20%3E%20skb-%3Elen)%3B%0A%09skb-%3Elen%20-%3D%20len%3B%0A%09BUG_ON(skb-%3Elen%20%3C%20skb-%3Edata_len)%3B%0A%09skb_postpull_rcsum(skb%2C%20skb-%3Edata%2C%20len)%3B%0A%09return%20skb-%3Edata%20%2B%3D%20len%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_pull_rcsum)%3B%0A%0A%2F**%0A%20*%09skb_segment%20-%20Perform%20protocol%20segmentation%20on%20skb.%0A%20*%09%40skb%3A%20buffer%20to%20segment%0A%20*%09%40features%3A%20features%20for%20the%20output%20path%20(see%20dev-%3Efeatures)%0A%20*%0A%20*%09This%20function%20performs%20segmentation%20on%20the%20given%20skb.%20%20It%20returns%0A%20*%09a%20pointer%20to%20the%20first%20in%20a%20list%20of%20new%20skbs%20for%20the%20segments.%0A%20*%09In%20case%20of%20error%20it%20returns%20ERR_PTR(err).%0A%20*%2F%0Astruct%20sk_buff%20*skb_segment(struct%20sk_buff%20*skb%2C%20netdev_features_t%20features)%0A%7B%0A%09struct%20sk_buff%20*segs%20%3D%20NULL%3B%0A%09struct%20sk_buff%20*tail%20%3D%20NULL%3B%0A%09struct%20sk_buff%20*fskb%20%3D%20skb_shinfo(skb)-%3Efrag_list%3B%0A%09unsigned%20int%20mss%20%3D%20skb_shinfo(skb)-%3Egso_size%3B%0A%09unsigned%20int%20doffset%20%3D%20skb-%3Edata%20-%20skb_mac_header(skb)%3B%0A%09unsigned%20int%20offset%20%3D%20doffset%3B%0A%09unsigned%20int%20tnl_hlen%20%3D%20skb_tnl_header_len(skb)%3B%0A%09unsigned%20int%20headroom%3B%0A%09unsigned%20int%20len%3B%0A%09__be16%20proto%3B%0A%09bool%20csum%3B%0A%09int%20sg%20%3D%20!!(features%20%26%20NETIF_F_SG)%3B%0A%09int%20nfrags%20%3D%20skb_shinfo(skb)-%3Enr_frags%3B%0A%09int%20err%20%3D%20-ENOMEM%3B%0A%09int%20i%20%3D%200%3B%0A%09int%20pos%3B%0A%0A%09proto%20%3D%20skb_network_protocol(skb)%3B%0A%09if%20(unlikely(!proto))%0A%09%09return%20ERR_PTR(-EINVAL)%3B%0A%0A%09csum%20%3D%20!!can_checksum_protocol(features%2C%20proto)%3B%0A%09__skb_push(skb%2C%20doffset)%3B%0A%09headroom%20%3D%20skb_headroom(skb)%3B%0A%09pos%20%3D%20skb_headlen(skb)%3B%0A%0A%09do%20%7B%0A%09%09struct%20sk_buff%20*nskb%3B%0A%09%09skb_frag_t%20*frag%3B%0A%09%09int%20hsize%3B%0A%09%09int%20size%3B%0A%0A%09%09len%20%3D%20skb-%3Elen%20-%20offset%3B%0A%09%09if%20(len%20%3E%20mss)%0A%09%09%09len%20%3D%20mss%3B%0A%0A%09%09hsize%20%3D%20skb_headlen(skb)%20-%20offset%3B%0A%09%09if%20(hsize%20%3C%200)%0A%09%09%09hsize%20%3D%200%3B%0A%09%09if%20(hsize%20%3E%20len%20%7C%7C%20!sg)%0A%09%09%09hsize%20%3D%20len%3B%0A%0A%09%09if%20(!hsize%20%26%26%20i%20%3E%3D%20nfrags)%20%7B%0A%09%09%09BUG_ON(fskb-%3Elen%20!%3D%20len)%3B%0A%0A%09%09%09pos%20%2B%3D%20len%3B%0A%09%09%09nskb%20%3D%20skb_clone(fskb%2C%20GFP_ATOMIC)%3B%0A%09%09%09fskb%20%3D%20fskb-%3Enext%3B%0A%0A%09%09%09if%20(unlikely(!nskb))%0A%09%09%09%09goto%20err%3B%0A%0A%09%09%09hsize%20%3D%20skb_end_offset(nskb)%3B%0A%09%09%09if%20(skb_cow_head(nskb%2C%20doffset%20%2B%20headroom))%20%7B%0A%09%09%09%09kfree_skb(nskb)%3B%0A%09%09%09%09goto%20err%3B%0A%09%09%09%7D%0A%0A%09%09%09nskb-%3Etruesize%20%2B%3D%20skb_end_offset(nskb)%20-%20hsize%3B%0A%09%09%09skb_release_head_state(nskb)%3B%0A%09%09%09__skb_push(nskb%2C%20doffset)%3B%0A%09%09%7D%20else%20%7B%0A%09%09%09nskb%20%3D%20__alloc_skb(hsize%20%2B%20doffset%20%2B%20headroom%2C%0A%09%09%09%09%09%20%20%20GFP_ATOMIC%2C%20skb_alloc_rx_flag(skb)%2C%0A%09%09%09%09%09%20%20%20NUMA_NO_NODE)%3B%0A%0A%09%09%09if%20(unlikely(!nskb))%0A%09%09%09%09goto%20err%3B%0A%0A%09%09%09skb_reserve(nskb%2C%20headroom)%3B%0A%09%09%09__skb_put(nskb%2C%20doffset)%3B%0A%09%09%7D%0A%0A%09%09if%20(segs)%0A%09%09%09tail-%3Enext%20%3D%20nskb%3B%0A%09%09else%0A%09%09%09segs%20%3D%20nskb%3B%0A%09%09tail%20%3D%20nskb%3B%0A%0A%09%09__copy_skb_header(nskb%2C%20skb)%3B%0A%09%09nskb-%3Emac_len%20%3D%20skb-%3Emac_len%3B%0A%0A%09%09%2F*%20nskb%20and%20skb%20might%20have%20different%20headroom%20*%2F%0A%09%09if%20(nskb-%3Eip_summed%20%3D%3D%20CHECKSUM_PARTIAL)%0A%09%09%09nskb-%3Ecsum_start%20%2B%3D%20skb_headroom(nskb)%20-%20headroom%3B%0A%0A%09%09skb_reset_mac_header(nskb)%3B%0A%09%09skb_set_network_header(nskb%2C%20skb-%3Emac_len)%3B%0A%09%09nskb-%3Etransport_header%20%3D%20(nskb-%3Enetwork_header%20%2B%0A%09%09%09%09%09%20%20skb_network_header_len(skb))%3B%0A%0A%09%09skb_copy_from_linear_data_offset(skb%2C%20-tnl_hlen%2C%0A%09%09%09%09%09%09%20nskb-%3Edata%20-%20tnl_hlen%2C%0A%09%09%09%09%09%09%20doffset%20%2B%20tnl_hlen)%3B%0A%0A%09%09if%20(fskb%20!%3D%20skb_shinfo(skb)-%3Efrag_list)%0A%09%09%09goto%20perform_csum_check%3B%0A%0A%09%09if%20(!sg)%20%7B%0A%09%09%09nskb-%3Eip_summed%20%3D%20CHECKSUM_NONE%3B%0A%09%09%09nskb-%3Ecsum%20%3D%20skb_copy_and_csum_bits(skb%2C%20offset%2C%0A%09%09%09%09%09%09%09%20%20%20%20skb_put(nskb%2C%20len)%2C%0A%09%09%09%09%09%09%09%20%20%20%20len%2C%200)%3B%0A%09%09%09continue%3B%0A%09%09%7D%0A%0A%09%09frag%20%3D%20skb_shinfo(nskb)-%3Efrags%3B%0A%0A%09%09skb_copy_from_linear_data_offset(skb%2C%20offset%2C%0A%09%09%09%09%09%09%20skb_put(nskb%2C%20hsize)%2C%20hsize)%3B%0A%0A%09%09skb_shinfo(nskb)-%3Etx_flags%20%3D%20skb_shinfo(skb)-%3Etx_flags%20%26%20SKBTX_SHARED_FRAG%3B%0A%0A%09%09while%20(pos%20%3C%20offset%20%2B%20len%20%26%26%20i%20%3C%20nfrags)%20%7B%0A%09%09%09*frag%20%3D%20skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%09%09%09__skb_frag_ref(frag)%3B%0A%09%09%09size%20%3D%20skb_frag_size(frag)%3B%0A%0A%09%09%09if%20(pos%20%3C%20offset)%20%7B%0A%09%09%09%09frag-%3Epage_offset%20%2B%3D%20offset%20-%20pos%3B%0A%09%09%09%09skb_frag_size_sub(frag%2C%20offset%20-%20pos)%3B%0A%09%09%09%7D%0A%0A%09%09%09skb_shinfo(nskb)-%3Enr_frags%2B%2B%3B%0A%0A%09%09%09if%20(pos%20%2B%20size%20%3C%3D%20offset%20%2B%20len)%20%7B%0A%09%09%09%09i%2B%2B%3B%0A%09%09%09%09pos%20%2B%3D%20size%3B%0A%09%09%09%7D%20else%20%7B%0A%09%09%09%09skb_frag_size_sub(frag%2C%20pos%20%2B%20size%20-%20(offset%20%2B%20len))%3B%0A%09%09%09%09goto%20skip_fraglist%3B%0A%09%09%09%7D%0A%0A%09%09%09frag%2B%2B%3B%0A%09%09%7D%0A%0A%09%09if%20(pos%20%3C%20offset%20%2B%20len)%20%7B%0A%09%09%09struct%20sk_buff%20*fskb2%20%3D%20fskb%3B%0A%0A%09%09%09BUG_ON(pos%20%2B%20fskb-%3Elen%20!%3D%20offset%20%2B%20len)%3B%0A%0A%09%09%09pos%20%2B%3D%20fskb-%3Elen%3B%0A%09%09%09fskb%20%3D%20fskb-%3Enext%3B%0A%0A%09%09%09if%20(fskb2-%3Enext)%20%7B%0A%09%09%09%09fskb2%20%3D%20skb_clone(fskb2%2C%20GFP_ATOMIC)%3B%0A%09%09%09%09if%20(!fskb2)%0A%09%09%09%09%09goto%20err%3B%0A%09%09%09%7D%20else%0A%09%09%09%09skb_get(fskb2)%3B%0A%0A%09%09%09SKB_FRAG_ASSERT(nskb)%3B%0A%09%09%09skb_shinfo(nskb)-%3Efrag_list%20%3D%20fskb2%3B%0A%09%09%7D%0A%0Askip_fraglist%3A%0A%09%09nskb-%3Edata_len%20%3D%20len%20-%20hsize%3B%0A%09%09nskb-%3Elen%20%2B%3D%20nskb-%3Edata_len%3B%0A%09%09nskb-%3Etruesize%20%2B%3D%20nskb-%3Edata_len%3B%0A%0Aperform_csum_check%3A%0A%09%09if%20(!csum)%20%7B%0A%09%09%09nskb-%3Ecsum%20%3D%20skb_checksum(nskb%2C%20doffset%2C%0A%09%09%09%09%09%09%20%20nskb-%3Elen%20-%20doffset%2C%200)%3B%0A%09%09%09nskb-%3Eip_summed%20%3D%20CHECKSUM_NONE%3B%0A%09%09%7D%0A%09%7D%20while%20((offset%20%2B%3D%20len)%20%3C%20skb-%3Elen)%3B%0A%0A%09return%20segs%3B%0A%0Aerr%3A%0A%09while%20((skb%20%3D%20segs))%20%7B%0A%09%09segs%20%3D%20skb-%3Enext%3B%0A%09%09kfree_skb(skb)%3B%0A%09%7D%0A%09return%20ERR_PTR(err)%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_segment)%3B%0A%0Aint%20skb_gro_receive(struct%20sk_buff%20**head%2C%20struct%20sk_buff%20*skb)%0A%7B%0A%09struct%20sk_buff%20*p%20%3D%20*head%3B%0A%09struct%20sk_buff%20*nskb%3B%0A%09struct%20skb_shared_info%20*skbinfo%20%3D%20skb_shinfo(skb)%3B%0A%09struct%20skb_shared_info%20*pinfo%20%3D%20skb_shinfo(p)%3B%0A%09unsigned%20int%20headroom%3B%0A%09unsigned%20int%20len%20%3D%20skb_gro_len(skb)%3B%0A%09unsigned%20int%20offset%20%3D%20skb_gro_offset(skb)%3B%0A%09unsigned%20int%20headlen%20%3D%20skb_headlen(skb)%3B%0A%09unsigned%20int%20delta_truesize%3B%0A%0A%09if%20(p-%3Elen%20%2B%20len%20%3E%3D%2065536)%0A%09%09return%20-E2BIG%3B%0A%0A%09if%20(pinfo-%3Efrag_list)%0A%09%09goto%20merge%3B%0A%09else%20if%20(headlen%20%3C%3D%20offset)%20%7B%0A%09%09skb_frag_t%20*frag%3B%0A%09%09skb_frag_t%20*frag2%3B%0A%09%09int%20i%20%3D%20skbinfo-%3Enr_frags%3B%0A%09%09int%20nr_frags%20%3D%20pinfo-%3Enr_frags%20%2B%20i%3B%0A%0A%09%09offset%20-%3D%20headlen%3B%0A%0A%09%09if%20(nr_frags%20%3E%20MAX_SKB_FRAGS)%0A%09%09%09return%20-E2BIG%3B%0A%0A%09%09pinfo-%3Enr_frags%20%3D%20nr_frags%3B%0A%09%09skbinfo-%3Enr_frags%20%3D%200%3B%0A%0A%09%09frag%20%3D%20pinfo-%3Efrags%20%2B%20nr_frags%3B%0A%09%09frag2%20%3D%20skbinfo-%3Efrags%20%2B%20i%3B%0A%09%09do%20%7B%0A%09%09%09*--frag%20%3D%20*--frag2%3B%0A%09%09%7D%20while%20(--i)%3B%0A%0A%09%09frag-%3Epage_offset%20%2B%3D%20offset%3B%0A%09%09skb_frag_size_sub(frag%2C%20offset)%3B%0A%0A%09%09%2F*%20all%20fragments%20truesize%20%3A%20remove%20(head%20size%20%2B%20sk_buff)%20*%2F%0A%09%09delta_truesize%20%3D%20skb-%3Etruesize%20-%0A%09%09%09%09%20SKB_TRUESIZE(skb_end_offset(skb))%3B%0A%0A%09%09skb-%3Etruesize%20-%3D%20skb-%3Edata_len%3B%0A%09%09skb-%3Elen%20-%3D%20skb-%3Edata_len%3B%0A%09%09skb-%3Edata_len%20%3D%200%3B%0A%0A%09%09NAPI_GRO_CB(skb)-%3Efree%20%3D%20NAPI_GRO_FREE%3B%0A%09%09goto%20done%3B%0A%09%7D%20else%20if%20(skb-%3Ehead_frag)%20%7B%0A%09%09int%20nr_frags%20%3D%20pinfo-%3Enr_frags%3B%0A%09%09skb_frag_t%20*frag%20%3D%20pinfo-%3Efrags%20%2B%20nr_frags%3B%0A%09%09struct%20page%20*page%20%3D%20virt_to_head_page(skb-%3Ehead)%3B%0A%09%09unsigned%20int%20first_size%20%3D%20headlen%20-%20offset%3B%0A%09%09unsigned%20int%20first_offset%3B%0A%0A%09%09if%20(nr_frags%20%2B%201%20%2B%20skbinfo-%3Enr_frags%20%3E%20MAX_SKB_FRAGS)%0A%09%09%09return%20-E2BIG%3B%0A%0A%09%09first_offset%20%3D%20skb-%3Edata%20-%0A%09%09%09%20%20%20%20%20%20%20(unsigned%20char%20*)page_address(page)%20%2B%0A%09%09%09%20%20%20%20%20%20%20offset%3B%0A%0A%09%09pinfo-%3Enr_frags%20%3D%20nr_frags%20%2B%201%20%2B%20skbinfo-%3Enr_frags%3B%0A%0A%09%09frag-%3Epage.p%09%20%20%3D%20page%3B%0A%09%09frag-%3Epage_offset%20%3D%20first_offset%3B%0A%09%09skb_frag_size_set(frag%2C%20first_size)%3B%0A%0A%09%09memcpy(frag%20%2B%201%2C%20skbinfo-%3Efrags%2C%20sizeof(*frag)%20*%20skbinfo-%3Enr_frags)%3B%0A%09%09%2F*%20We%20dont%20need%20to%20clear%20skbinfo-%3Enr_frags%20here%20*%2F%0A%0A%09%09delta_truesize%20%3D%20skb-%3Etruesize%20-%20SKB_DATA_ALIGN(sizeof(struct%20sk_buff))%3B%0A%09%09NAPI_GRO_CB(skb)-%3Efree%20%3D%20NAPI_GRO_FREE_STOLEN_HEAD%3B%0A%09%09goto%20done%3B%0A%09%7D%20else%20if%20(skb_gro_len(p)%20!%3D%20pinfo-%3Egso_size)%0A%09%09return%20-E2BIG%3B%0A%0A%09headroom%20%3D%20skb_headroom(p)%3B%0A%09nskb%20%3D%20alloc_skb(headroom%20%2B%20skb_gro_offset(p)%2C%20GFP_ATOMIC)%3B%0A%09if%20(unlikely(!nskb))%0A%09%09return%20-ENOMEM%3B%0A%0A%09__copy_skb_header(nskb%2C%20p)%3B%0A%09nskb-%3Emac_len%20%3D%20p-%3Emac_len%3B%0A%0A%09skb_reserve(nskb%2C%20headroom)%3B%0A%09__skb_put(nskb%2C%20skb_gro_offset(p))%3B%0A%0A%09skb_set_mac_header(nskb%2C%20skb_mac_header(p)%20-%20p-%3Edata)%3B%0A%09skb_set_network_header(nskb%2C%20skb_network_offset(p))%3B%0A%09skb_set_transport_header(nskb%2C%20skb_transport_offset(p))%3B%0A%0A%09__skb_pull(p%2C%20skb_gro_offset(p))%3B%0A%09memcpy(skb_mac_header(nskb)%2C%20skb_mac_header(p)%2C%0A%09%20%20%20%20%20%20%20p-%3Edata%20-%20skb_mac_header(p))%3B%0A%0A%09skb_shinfo(nskb)-%3Efrag_list%20%3D%20p%3B%0A%09skb_shinfo(nskb)-%3Egso_size%20%3D%20pinfo-%3Egso_size%3B%0A%09pinfo-%3Egso_size%20%3D%200%3B%0A%09skb_header_release(p)%3B%0A%09NAPI_GRO_CB(nskb)-%3Elast%20%3D%20p%3B%0A%0A%09nskb-%3Edata_len%20%2B%3D%20p-%3Elen%3B%0A%09nskb-%3Etruesize%20%2B%3D%20p-%3Etruesize%3B%0A%09nskb-%3Elen%20%2B%3D%20p-%3Elen%3B%0A%0A%09*head%20%3D%20nskb%3B%0A%09nskb-%3Enext%20%3D%20p-%3Enext%3B%0A%09p-%3Enext%20%3D%20NULL%3B%0A%0A%09p%20%3D%20nskb%3B%0A%0Amerge%3A%0A%09delta_truesize%20%3D%20skb-%3Etruesize%3B%0A%09if%20(offset%20%3E%20headlen)%20%7B%0A%09%09unsigned%20int%20eat%20%3D%20offset%20-%20headlen%3B%0A%0A%09%09skbinfo-%3Efrags%5B0%5D.page_offset%20%2B%3D%20eat%3B%0A%09%09skb_frag_size_sub(%26skbinfo-%3Efrags%5B0%5D%2C%20eat)%3B%0A%09%09skb-%3Edata_len%20-%3D%20eat%3B%0A%09%09skb-%3Elen%20-%3D%20eat%3B%0A%09%09offset%20%3D%20headlen%3B%0A%09%7D%0A%0A%09__skb_pull(skb%2C%20offset)%3B%0A%0A%09NAPI_GRO_CB(p)-%3Elast-%3Enext%20%3D%20skb%3B%0A%09NAPI_GRO_CB(p)-%3Elast%20%3D%20skb%3B%0A%09skb_header_release(skb)%3B%0A%0Adone%3A%0A%09NAPI_GRO_CB(p)-%3Ecount%2B%2B%3B%0A%09p-%3Edata_len%20%2B%3D%20len%3B%0A%09p-%3Etruesize%20%2B%3D%20delta_truesize%3B%0A%09p-%3Elen%20%2B%3D%20len%3B%0A%0A%09NAPI_GRO_CB(skb)-%3Esame_flow%20%3D%201%3B%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_gro_receive)%3B%0A%0Avoid%20__init%20skb_init(void)%0A%7B%0A%09skbuff_head_cache%20%3D%20kmem_cache_create(%22skbuff_head_cache%22%2C%0A%09%09%09%09%09%20%20%20%20%20%20sizeof(struct%20sk_buff)%2C%0A%09%09%09%09%09%20%20%20%20%20%200%2C%0A%09%09%09%09%09%20%20%20%20%20%20SLAB_HWCACHE_ALIGN%7CSLAB_PANIC%2C%0A%09%09%09%09%09%20%20%20%20%20%20NULL)%3B%0A%09skbuff_fclone_cache%20%3D%20kmem_cache_create(%22skbuff_fclone_cache%22%2C%0A%09%09%09%09%09%09(2*sizeof(struct%20sk_buff))%20%2B%0A%09%09%09%09%09%09sizeof(atomic_t)%2C%0A%09%09%09%09%09%090%2C%0A%09%09%09%09%09%09SLAB_HWCACHE_ALIGN%7CSLAB_PANIC%2C%0A%09%09%09%09%09%09NULL)%3B%0A%7D%0A%0A%2F**%0A%20*%09skb_to_sgvec%20-%20Fill%20a%20scatter-gather%20list%20from%20a%20socket%20buffer%0A%20*%09%40skb%3A%20Socket%20buffer%20containing%20the%20buffers%20to%20be%20mapped%0A%20*%09%40sg%3A%20The%20scatter-gather%20list%20to%20map%20into%0A%20*%09%40offset%3A%20The%20offset%20into%20the%20buffer's%20contents%20to%20start%20mapping%0A%20*%09%40len%3A%20Length%20of%20buffer%20space%20to%20be%20mapped%0A%20*%0A%20*%09Fill%20the%20specified%20scatter-gather%20list%20with%20mappings%2Fpointers%20into%20a%0A%20*%09region%20of%20the%20buffer%20space%20attached%20to%20a%20socket%20buffer.%0A%20*%2F%0Astatic%20int%0A__skb_to_sgvec(struct%20sk_buff%20*skb%2C%20struct%20scatterlist%20*sg%2C%20int%20offset%2C%20int%20len)%0A%7B%0A%09int%20start%20%3D%20skb_headlen(skb)%3B%0A%09int%20i%2C%20copy%20%3D%20start%20-%20offset%3B%0A%09struct%20sk_buff%20*frag_iter%3B%0A%09int%20elt%20%3D%200%3B%0A%0A%09if%20(copy%20%3E%200)%20%7B%0A%09%09if%20(copy%20%3E%20len)%0A%09%09%09copy%20%3D%20len%3B%0A%09%09sg_set_buf(sg%2C%20skb-%3Edata%20%2B%20offset%2C%20copy)%3B%0A%09%09elt%2B%2B%3B%0A%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09return%20elt%3B%0A%09%09offset%20%2B%3D%20copy%3B%0A%09%7D%0A%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(skb)-%3Enr_frags%3B%20i%2B%2B)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20skb_frag_size(%26skb_shinfo(skb)-%3Efrags%5Bi%5D)%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09skb_frag_t%20*frag%20%3D%20%26skb_shinfo(skb)-%3Efrags%5Bi%5D%3B%0A%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09sg_set_page(%26sg%5Belt%5D%2C%20skb_frag_page(frag)%2C%20copy%2C%0A%09%09%09%09%09frag-%3Epage_offset%2Boffset-start)%3B%0A%09%09%09elt%2B%2B%3B%0A%09%09%09if%20(!(len%20-%3D%20copy))%0A%09%09%09%09return%20elt%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%0A%09skb_walk_frags(skb%2C%20frag_iter)%20%7B%0A%09%09int%20end%3B%0A%0A%09%09WARN_ON(start%20%3E%20offset%20%2B%20len)%3B%0A%0A%09%09end%20%3D%20start%20%2B%20frag_iter-%3Elen%3B%0A%09%09if%20((copy%20%3D%20end%20-%20offset)%20%3E%200)%20%7B%0A%09%09%09if%20(copy%20%3E%20len)%0A%09%09%09%09copy%20%3D%20len%3B%0A%09%09%09elt%20%2B%3D%20__skb_to_sgvec(frag_iter%2C%20sg%2Belt%2C%20offset%20-%20start%2C%0A%09%09%09%09%09%20%20%20%20%20%20copy)%3B%0A%09%09%09if%20((len%20-%3D%20copy)%20%3D%3D%200)%0A%09%09%09%09return%20elt%3B%0A%09%09%09offset%20%2B%3D%20copy%3B%0A%09%09%7D%0A%09%09start%20%3D%20end%3B%0A%09%7D%0A%09BUG_ON(len)%3B%0A%09return%20elt%3B%0A%7D%0A%0Aint%20skb_to_sgvec(struct%20sk_buff%20*skb%2C%20struct%20scatterlist%20*sg%2C%20int%20offset%2C%20int%20len)%0A%7B%0A%09int%20nsg%20%3D%20__skb_to_sgvec(skb%2C%20sg%2C%20offset%2C%20len)%3B%0A%0A%09sg_mark_end(%26sg%5Bnsg%20-%201%5D)%3B%0A%0A%09return%20nsg%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_to_sgvec)%3B%0A%0A%2F**%0A%20*%09skb_cow_data%20-%20Check%20that%20a%20socket%20buffer's%20data%20buffers%20are%20writable%0A%20*%09%40skb%3A%20The%20socket%20buffer%20to%20check.%0A%20*%09%40tailbits%3A%20Amount%20of%20trailing%20space%20to%20be%20added%0A%20*%09%40trailer%3A%20Returned%20pointer%20to%20the%20skb%20where%20the%20%40tailbits%20space%20begins%0A%20*%0A%20*%09Make%20sure%20that%20the%20data%20buffers%20attached%20to%20a%20socket%20buffer%20are%0A%20*%09writable.%20If%20they%20are%20not%2C%20private%20copies%20are%20made%20of%20the%20data%20buffers%0A%20*%09and%20the%20socket%20buffer%20is%20set%20to%20use%20these%20instead.%0A%20*%0A%20*%09If%20%40tailbits%20is%20given%2C%20make%20sure%20that%20there%20is%20space%20to%20write%20%40tailbits%0A%20*%09bytes%20of%20data%20beyond%20current%20end%20of%20socket%20buffer.%20%20%40trailer%20will%20be%0A%20*%09set%20to%20point%20to%20the%20skb%20in%20which%20this%20space%20begins.%0A%20*%0A%20*%09The%20number%20of%20scatterlist%20elements%20required%20to%20completely%20map%20the%0A%20*%09COW'd%20and%20extended%20socket%20buffer%20will%20be%20returned.%0A%20*%2F%0Aint%20skb_cow_data(struct%20sk_buff%20*skb%2C%20int%20tailbits%2C%20struct%20sk_buff%20**trailer)%0A%7B%0A%09int%20copyflag%3B%0A%09int%20elt%3B%0A%09struct%20sk_buff%20*skb1%2C%20**skb_p%3B%0A%0A%09%2F*%20If%20skb%20is%20cloned%20or%20its%20head%20is%20paged%2C%20reallocate%0A%09%20*%20head%20pulling%20out%20all%20the%20pages%20(pages%20are%20considered%20not%20writable%0A%09%20*%20at%20the%20moment%20even%20if%20they%20are%20anonymous).%0A%09%20*%2F%0A%09if%20((skb_cloned(skb)%20%7C%7C%20skb_shinfo(skb)-%3Enr_frags)%20%26%26%0A%09%20%20%20%20__pskb_pull_tail(skb%2C%20skb_pagelen(skb)-skb_headlen(skb))%20%3D%3D%20NULL)%0A%09%09return%20-ENOMEM%3B%0A%0A%09%2F*%20Easy%20case.%20Most%20of%20packets%20will%20go%20this%20way.%20*%2F%0A%09if%20(!skb_has_frag_list(skb))%20%7B%0A%09%09%2F*%20A%20little%20of%20trouble%2C%20not%20enough%20of%20space%20for%20trailer.%0A%09%09%20*%20This%20should%20not%20happen%2C%20when%20stack%20is%20tuned%20to%20generate%0A%09%09%20*%20good%20frames.%20OK%2C%20on%20miss%20we%20reallocate%20and%20reserve%20even%20more%0A%09%09%20*%20space%2C%20128%20bytes%20is%20fair.%20*%2F%0A%0A%09%09if%20(skb_tailroom(skb)%20%3C%20tailbits%20%26%26%0A%09%09%20%20%20%20pskb_expand_head(skb%2C%200%2C%20tailbits-skb_tailroom(skb)%2B128%2C%20GFP_ATOMIC))%0A%09%09%09return%20-ENOMEM%3B%0A%0A%09%09%2F*%20Voila!%20*%2F%0A%09%09*trailer%20%3D%20skb%3B%0A%09%09return%201%3B%0A%09%7D%0A%0A%09%2F*%20Misery.%20We%20are%20in%20troubles%2C%20going%20to%20mincer%20fragments...%20*%2F%0A%0A%09elt%20%3D%201%3B%0A%09skb_p%20%3D%20%26skb_shinfo(skb)-%3Efrag_list%3B%0A%09copyflag%20%3D%200%3B%0A%0A%09while%20((skb1%20%3D%20*skb_p)%20!%3D%20NULL)%20%7B%0A%09%09int%20ntail%20%3D%200%3B%0A%0A%09%09%2F*%20The%20fragment%20is%20partially%20pulled%20by%20someone%2C%0A%09%09%20*%20this%20can%20happen%20on%20input.%20Copy%20it%20and%20everything%0A%09%09%20*%20after%20it.%20*%2F%0A%0A%09%09if%20(skb_shared(skb1))%0A%09%09%09copyflag%20%3D%201%3B%0A%0A%09%09%2F*%20If%20the%20skb%20is%20the%20last%2C%20worry%20about%20trailer.%20*%2F%0A%0A%09%09if%20(skb1-%3Enext%20%3D%3D%20NULL%20%26%26%20tailbits)%20%7B%0A%09%09%09if%20(skb_shinfo(skb1)-%3Enr_frags%20%7C%7C%0A%09%09%09%20%20%20%20skb_has_frag_list(skb1)%20%7C%7C%0A%09%09%09%20%20%20%20skb_tailroom(skb1)%20%3C%20tailbits)%0A%09%09%09%09ntail%20%3D%20tailbits%20%2B%20128%3B%0A%09%09%7D%0A%0A%09%09if%20(copyflag%20%7C%7C%0A%09%09%20%20%20%20skb_cloned(skb1)%20%7C%7C%0A%09%09%20%20%20%20ntail%20%7C%7C%0A%09%09%20%20%20%20skb_shinfo(skb1)-%3Enr_frags%20%7C%7C%0A%09%09%20%20%20%20skb_has_frag_list(skb1))%20%7B%0A%09%09%09struct%20sk_buff%20*skb2%3B%0A%0A%09%09%09%2F*%20butterfly%2C%20we%20are%20miserable%20poor%20guys...%20*%2F%0A%09%09%09if%20(ntail%20%3D%3D%200)%0A%09%09%09%09skb2%20%3D%20skb_copy(skb1%2C%20GFP_ATOMIC)%3B%0A%09%09%09else%0A%09%09%09%09skb2%20%3D%20skb_copy_expand(skb1%2C%0A%09%09%09%09%09%09%20%20%20%20%20%20%20skb_headroom(skb1)%2C%0A%09%09%09%09%09%09%20%20%20%20%20%20%20ntail%2C%0A%09%09%09%09%09%09%20%20%20%20%20%20%20GFP_ATOMIC)%3B%0A%09%09%09if%20(unlikely(skb2%20%3D%3D%20NULL))%0A%09%09%09%09return%20-ENOMEM%3B%0A%0A%09%09%09if%20(skb1-%3Esk)%0A%09%09%09%09skb_set_owner_w(skb2%2C%20skb1-%3Esk)%3B%0A%0A%09%09%09%2F*%20Looking%20around.%20Are%20we%20still%20alive%3F%0A%09%09%09%20*%20OK%2C%20link%20new%20skb%2C%20drop%20old%20one%20*%2F%0A%0A%09%09%09skb2-%3Enext%20%3D%20skb1-%3Enext%3B%0A%09%09%09*skb_p%20%3D%20skb2%3B%0A%09%09%09kfree_skb(skb1)%3B%0A%09%09%09skb1%20%3D%20skb2%3B%0A%09%09%7D%0A%09%09elt%2B%2B%3B%0A%09%09*trailer%20%3D%20skb1%3B%0A%09%09skb_p%20%3D%20%26skb1-%3Enext%3B%0A%09%7D%0A%0A%09return%20elt%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_cow_data)%3B%0A%0Astatic%20void%20sock_rmem_free(struct%20sk_buff%20*skb)%0A%7B%0A%09struct%20sock%20*sk%20%3D%20skb-%3Esk%3B%0A%0A%09atomic_sub(skb-%3Etruesize%2C%20%26sk-%3Esk_rmem_alloc)%3B%0A%7D%0A%0A%2F*%0A%20*%20Note%3A%20We%20dont%20mem%20charge%20error%20packets%20(no%20sk_forward_alloc%20changes)%0A%20*%2F%0Aint%20sock_queue_err_skb(struct%20sock%20*sk%2C%20struct%20sk_buff%20*skb)%0A%7B%0A%09int%20len%20%3D%20skb-%3Elen%3B%0A%0A%09if%20(atomic_read(%26sk-%3Esk_rmem_alloc)%20%2B%20skb-%3Etruesize%20%3E%3D%0A%09%20%20%20%20(unsigned%20int)sk-%3Esk_rcvbuf)%0A%09%09return%20-ENOMEM%3B%0A%0A%09skb_orphan(skb)%3B%0A%09skb-%3Esk%20%3D%20sk%3B%0A%09skb-%3Edestructor%20%3D%20sock_rmem_free%3B%0A%09atomic_add(skb-%3Etruesize%2C%20%26sk-%3Esk_rmem_alloc)%3B%0A%0A%09%2F*%20before%20exiting%20rcu%20section%2C%20make%20sure%20dst%20is%20refcounted%20*%2F%0A%09skb_dst_force(skb)%3B%0A%0A%09skb_queue_tail(%26sk-%3Esk_error_queue%2C%20skb)%3B%0A%09if%20(!sock_flag(sk%2C%20SOCK_DEAD))%0A%09%09sk-%3Esk_data_ready(sk%2C%20len)%3B%0A%09return%200%3B%0A%7D%0AEXPORT_SYMBOL(sock_queue_err_skb)%3B%0A%0Avoid%20skb_tstamp_tx(struct%20sk_buff%20*orig_skb%2C%0A%09%09struct%20skb_shared_hwtstamps%20*hwtstamps)%0A%7B%0A%09struct%20sock%20*sk%20%3D%20orig_skb-%3Esk%3B%0A%09struct%20sock_exterr_skb%20*serr%3B%0A%09struct%20sk_buff%20*skb%3B%0A%09int%20err%3B%0A%0A%09if%20(!sk)%0A%09%09return%3B%0A%0A%09if%20(hwtstamps)%20%7B%0A%09%09*skb_hwtstamps(orig_skb)%20%3D%0A%09%09%09*hwtstamps%3B%0A%09%7D%20else%20%7B%0A%09%09%2F*%0A%09%09%20*%20no%20hardware%20time%20stamps%20available%2C%0A%09%09%20*%20so%20keep%20the%20shared%20tx_flags%20and%20only%0A%09%09%20*%20store%20software%20time%20stamp%0A%09%09%20*%2F%0A%09%09orig_skb-%3Etstamp%20%3D%20ktime_get_real()%3B%0A%09%7D%0A%0A%09skb%20%3D%20skb_clone(orig_skb%2C%20GFP_ATOMIC)%3B%0A%09if%20(!skb)%0A%09%09return%3B%0A%0A%09serr%20%3D%20SKB_EXT_ERR(skb)%3B%0A%09memset(serr%2C%200%2C%20sizeof(*serr))%3B%0A%09serr-%3Eee.ee_errno%20%3D%20ENOMSG%3B%0A%09serr-%3Eee.ee_origin%20%3D%20SO_EE_ORIGIN_TIMESTAMPING%3B%0A%0A%09err%20%3D%20sock_queue_err_skb(sk%2C%20skb)%3B%0A%0A%09if%20(err)%0A%09%09kfree_skb(skb)%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_tstamp_tx)%3B%0A%0Avoid%20skb_complete_wifi_ack(struct%20sk_buff%20*skb%2C%20bool%20acked)%0A%7B%0A%09struct%20sock%20*sk%20%3D%20skb-%3Esk%3B%0A%09struct%20sock_exterr_skb%20*serr%3B%0A%09int%20err%3B%0A%0A%09skb-%3Ewifi_acked_valid%20%3D%201%3B%0A%09skb-%3Ewifi_acked%20%3D%20acked%3B%0A%0A%09serr%20%3D%20SKB_EXT_ERR(skb)%3B%0A%09memset(serr%2C%200%2C%20sizeof(*serr))%3B%0A%09serr-%3Eee.ee_errno%20%3D%20ENOMSG%3B%0A%09serr-%3Eee.ee_origin%20%3D%20SO_EE_ORIGIN_TXSTATUS%3B%0A%0A%09err%20%3D%20sock_queue_err_skb(sk%2C%20skb)%3B%0A%09if%20(err)%0A%09%09kfree_skb(skb)%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_complete_wifi_ack)%3B%0A%0A%0A%2F**%0A%20*%20skb_partial_csum_set%20-%20set%20up%20and%20verify%20partial%20csum%20values%20for%20packet%0A%20*%20%40skb%3A%20the%20skb%20to%20set%0A%20*%20%40start%3A%20the%20number%20of%20bytes%20after%20skb-%3Edata%20to%20start%20checksumming.%0A%20*%20%40off%3A%20the%20offset%20from%20start%20to%20place%20the%20checksum.%0A%20*%0A%20*%20For%20untrusted%20partially-checksummed%20packets%2C%20we%20need%20to%20make%20sure%20the%20values%0A%20*%20for%20skb-%3Ecsum_start%20and%20skb-%3Ecsum_offset%20are%20valid%20so%20we%20don't%20oops.%0A%20*%0A%20*%20This%20function%20checks%20and%20sets%20those%20values%20and%20skb-%3Eip_summed%3A%20if%20this%0A%20*%20returns%20false%20you%20should%20drop%20the%20packet.%0A%20*%2F%0Abool%20skb_partial_csum_set(struct%20sk_buff%20*skb%2C%20u16%20start%2C%20u16%20off)%0A%7B%0A%09if%20(unlikely(start%20%3E%20skb_headlen(skb))%20%7C%7C%0A%09%20%20%20%20unlikely((int)start%20%2B%20off%20%3E%20skb_headlen(skb)%20-%202))%20%7B%0A%09%09net_warn_ratelimited(%22bad%20partial%20csum%3A%20csum%3D%25u%2F%25u%20len%3D%25u%5Cn%22%2C%0A%09%09%09%09%20%20%20%20%20start%2C%20off%2C%20skb_headlen(skb))%3B%0A%09%09return%20false%3B%0A%09%7D%0A%09skb-%3Eip_summed%20%3D%20CHECKSUM_PARTIAL%3B%0A%09skb-%3Ecsum_start%20%3D%20skb_headroom(skb)%20%2B%20start%3B%0A%09skb-%3Ecsum_offset%20%3D%20off%3B%0A%09skb_set_transport_header(skb%2C%20start)%3B%0A%09return%20true%3B%0A%7D%0AEXPORT_SYMBOL_GPL(skb_partial_csum_set)%3B%0A%0Avoid%20__skb_warn_lro_forwarding(const%20struct%20sk_buff%20*skb)%0A%7B%0A%09net_warn_ratelimited(%22%25s%3A%20received%20packets%20cannot%20be%20forwarded%20while%20LRO%20is%20enabled%5Cn%22%2C%0A%09%09%09%20%20%20%20%20skb-%3Edev-%3Ename)%3B%0A%7D%0AEXPORT_SYMBOL(__skb_warn_lro_forwarding)%3B%0A%0Avoid%20kfree_skb_partial(struct%20sk_buff%20*skb%2C%20bool%20head_stolen)%0A%7B%0A%09if%20(head_stolen)%20%7B%0A%09%09skb_release_head_state(skb)%3B%0A%09%09kmem_cache_free(skbuff_head_cache%2C%20skb)%3B%0A%09%7D%20else%20%7B%0A%09%09__kfree_skb(skb)%3B%0A%09%7D%0A%7D%0AEXPORT_SYMBOL(kfree_skb_partial)%3B%0A%0A%2F**%0A%20*%20skb_try_coalesce%20-%20try%20to%20merge%20skb%20to%20prior%20one%0A%20*%20%40to%3A%20prior%20buffer%0A%20*%20%40from%3A%20buffer%20to%20add%0A%20*%20%40fragstolen%3A%20pointer%20to%20boolean%0A%20*%20%40delta_truesize%3A%20how%20much%20more%20was%20allocated%20than%20was%20requested%0A%20*%2F%0Abool%20skb_try_coalesce(struct%20sk_buff%20*to%2C%20struct%20sk_buff%20*from%2C%0A%09%09%20%20%20%20%20%20bool%20*fragstolen%2C%20int%20*delta_truesize)%0A%7B%0A%09int%20i%2C%20delta%2C%20len%20%3D%20from-%3Elen%3B%0A%0A%09*fragstolen%20%3D%20false%3B%0A%0A%09if%20(skb_cloned(to))%0A%09%09return%20false%3B%0A%0A%09if%20(len%20%3C%3D%20skb_tailroom(to))%20%7B%0A%09%09BUG_ON(skb_copy_bits(from%2C%200%2C%20skb_put(to%2C%20len)%2C%20len))%3B%0A%09%09*delta_truesize%20%3D%200%3B%0A%09%09return%20true%3B%0A%09%7D%0A%0A%09if%20(skb_has_frag_list(to)%20%7C%7C%20skb_has_frag_list(from))%0A%09%09return%20false%3B%0A%0A%09if%20(skb_headlen(from)%20!%3D%200)%20%7B%0A%09%09struct%20page%20*page%3B%0A%09%09unsigned%20int%20offset%3B%0A%0A%09%09if%20(skb_shinfo(to)-%3Enr_frags%20%2B%0A%09%09%20%20%20%20skb_shinfo(from)-%3Enr_frags%20%3E%3D%20MAX_SKB_FRAGS)%0A%09%09%09return%20false%3B%0A%0A%09%09if%20(skb_head_is_locked(from))%0A%09%09%09return%20false%3B%0A%0A%09%09delta%20%3D%20from-%3Etruesize%20-%20SKB_DATA_ALIGN(sizeof(struct%20sk_buff))%3B%0A%0A%09%09page%20%3D%20virt_to_head_page(from-%3Ehead)%3B%0A%09%09offset%20%3D%20from-%3Edata%20-%20(unsigned%20char%20*)page_address(page)%3B%0A%0A%09%09skb_fill_page_desc(to%2C%20skb_shinfo(to)-%3Enr_frags%2C%0A%09%09%09%09%20%20%20page%2C%20offset%2C%20skb_headlen(from))%3B%0A%09%09*fragstolen%20%3D%20true%3B%0A%09%7D%20else%20%7B%0A%09%09if%20(skb_shinfo(to)-%3Enr_frags%20%2B%0A%09%09%20%20%20%20skb_shinfo(from)-%3Enr_frags%20%3E%20MAX_SKB_FRAGS)%0A%09%09%09return%20false%3B%0A%0A%09%09delta%20%3D%20from-%3Etruesize%20-%20SKB_TRUESIZE(skb_end_offset(from))%3B%0A%09%7D%0A%0A%09WARN_ON_ONCE(delta%20%3C%20len)%3B%0A%0A%09memcpy(skb_shinfo(to)-%3Efrags%20%2B%20skb_shinfo(to)-%3Enr_frags%2C%0A%09%20%20%20%20%20%20%20skb_shinfo(from)-%3Efrags%2C%0A%09%20%20%20%20%20%20%20skb_shinfo(from)-%3Enr_frags%20*%20sizeof(skb_frag_t))%3B%0A%09skb_shinfo(to)-%3Enr_frags%20%2B%3D%20skb_shinfo(from)-%3Enr_frags%3B%0A%0A%09if%20(!skb_cloned(from))%0A%09%09skb_shinfo(from)-%3Enr_frags%20%3D%200%3B%0A%0A%09%2F*%20if%20the%20skb%20is%20not%20cloned%20this%20does%20nothing%0A%09%20*%20since%20we%20set%20nr_frags%20to%200.%0A%09%20*%2F%0A%09for%20(i%20%3D%200%3B%20i%20%3C%20skb_shinfo(from)-%3Enr_frags%3B%20i%2B%2B)%0A%09%09skb_frag_ref(from%2C%20i)%3B%0A%0A%09to-%3Etruesize%20%2B%3D%20delta%3B%0A%09to-%3Elen%20%2B%3D%20len%3B%0A%09to-%3Edata_len%20%2B%3D%20len%3B%0A%0A%09*delta_truesize%20%3D%20delta%3B%0A%09return%20true%3B%0A%7D%0AEXPORT_SYMBOL(skb_try_coalesce)%3B%0A
